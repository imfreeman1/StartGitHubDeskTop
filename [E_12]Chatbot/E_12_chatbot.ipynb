{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"E_12_chatbot.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyMY/yu9HD8uJbqmBKXaEtVQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 챗봇을 만들어보자  \n","----  \n","####부제 : 친구가 필요해  \n","  \n","####목차  \n"," - 베이스 라인\n"," - 에폭 200\n"," - 파라미터 변경"],"metadata":{"id":"Us07hVPzxE3v"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8WX6ZiriOVad","executionInfo":{"status":"ok","timestamp":1645497645716,"user_tz":-540,"elapsed":3183,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"c828ee0c-d8e7-42f5-be10-69b40fce1098"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import tensorflow as tf\n","import tensorflow_datasets as tfds\n","import os\n","import re\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["dataset_file_path = '/content/drive/MyDrive/colab/Word/ChatbotData.csv'\n","dataset_file_path"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"ev6eD35aQcRE","executionInfo":{"status":"ok","timestamp":1645497645719,"user_tz":-540,"elapsed":22,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"8cdc8da4-305d-4f79-8765-dc358e589638"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/colab/Word/ChatbotData.csv'"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["# 포지셔널 인코딩 레이어\n","class PositionalEncoding(tf.keras.layers.Layer):\n","\n","  def __init__(self, position, d_model):\n","    super(PositionalEncoding, self).__init__()\n","    self.pos_encoding = self.positional_encoding(position, d_model)\n","\n","  def get_angles(self, position, i, d_model):\n","    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n","    return position * angles\n","\n","  def positional_encoding(self, position, d_model):\n","    # 각도 배열 생성\n","    angle_rads = self.get_angles(\n","        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n","        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n","        d_model=d_model)\n","\n","    # 배열의 짝수 인덱스에는 sin 함수 적용\n","    sines = tf.math.sin(angle_rads[:, 0::2])\n","    # 배열의 홀수 인덱스에는 cosine 함수 적용\n","    cosines = tf.math.cos(angle_rads[:, 1::2])\n","\n","    # sin과 cosine이 교차되도록 재배열\n","    pos_encoding = tf.stack([sines, cosines], axis=0)\n","    pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n","    pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n","\n","    pos_encoding = pos_encoding[tf.newaxis, ...]\n","    return tf.cast(pos_encoding, tf.float32)\n","\n","  def call(self, inputs):\n","    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n","\n","# 스케일드 닷 프로덕트 어텐션 함수\n","def scaled_dot_product_attention(query, key, value, mask):\n","  # 어텐션 가중치는 Q와 K의 닷 프로덕트\n","  matmul_qk = tf.matmul(query, key, transpose_b=True)\n","\n","  # 가중치를 정규화\n","  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n","  logits = matmul_qk / tf.math.sqrt(depth)\n","\n","  # 패딩에 마스크 추가\n","  if mask is not None:\n","    logits += (mask * -1e9)\n","\n","  # softmax적용\n","  attention_weights = tf.nn.softmax(logits, axis=-1)\n","\n","  # 최종 어텐션은 가중치와 V의 닷 프로덕트\n","  output = tf.matmul(attention_weights, value)\n","  return output\n","\n","# 멀티 헤드 어텐션 함수\n","class MultiHeadAttention(tf.keras.layers.Layer):\n","\n","  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n","    super(MultiHeadAttention, self).__init__(name=name)\n","    self.num_heads = num_heads\n","    self.d_model = d_model\n","\n","    assert d_model % self.num_heads == 0\n","\n","    self.depth = d_model // self.num_heads\n","\n","    self.query_dense = tf.keras.layers.Dense(units=d_model)\n","    self.key_dense = tf.keras.layers.Dense(units=d_model)\n","    self.value_dense = tf.keras.layers.Dense(units=d_model)\n","\n","    self.dense = tf.keras.layers.Dense(units=d_model)\n","\n","  def split_heads(self, inputs, batch_size):\n","    inputs = tf.reshape(\n","        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n","    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n","\n","  def call(self, inputs):\n","    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n","        'value'], inputs['mask']\n","    batch_size = tf.shape(query)[0]\n","\n","    # Q, K, V에 각각 Dense를 적용합니다\n","    query = self.query_dense(query)\n","    key = self.key_dense(key)\n","    value = self.value_dense(value)\n","\n","    # 병렬 연산을 위한 머리를 여러 개 만듭니다\n","    query = self.split_heads(query, batch_size)\n","    key = self.split_heads(key, batch_size)\n","    value = self.split_heads(value, batch_size)\n","\n","    # 스케일드 닷 프로덕트 어텐션 함수\n","    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n","\n","    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n","\n","    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n","    concat_attention = tf.reshape(scaled_attention,\n","                                  (batch_size, -1, self.d_model))\n","\n","    # 최종 결과에도 Dense를 한 번 더 적용합니다\n","    outputs = self.dense(concat_attention)\n","\n","    return outputs"],"metadata":{"id":"gM-Bh5UlRNX7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_padding_mask(x):\n","  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n","  # (batch_size, 1, 1, sequence length)\n","  return mask[:, tf.newaxis, tf.newaxis, :]"],"metadata":{"id":"zvd76kfGRRIf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_look_ahead_mask(x):\n","  seq_len = tf.shape(x)[1]\n","  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n","  padding_mask = create_padding_mask(x)\n","  return tf.maximum(look_ahead_mask, padding_mask)"],"metadata":{"id":"aWe-5k8tRSPP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 인코더 하나의 레이어를 함수로 구현.\n","# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n","def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n","  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n","\n","  # 패딩 마스크 사용\n","  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n","\n","  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n","  attention = MultiHeadAttention(\n","      d_model, num_heads, name=\"attention\")({\n","          'query': inputs,\n","          'key': inputs,\n","          'value': inputs,\n","          'mask': padding_mask\n","      })\n","\n","  # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n","  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n","  attention = tf.keras.layers.LayerNormalization(\n","      epsilon=1e-6)(inputs + attention)\n","\n","  # 두 번째 서브 레이어 : 2개의 완전연결층\n","  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n","  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n","\n","  # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n","  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n","  outputs = tf.keras.layers.LayerNormalization(\n","      epsilon=1e-6)(attention + outputs)\n","\n","  return tf.keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)\n","\n","def encoder(vocab_size,\n","            num_layers,\n","            units,\n","            d_model,\n","            num_heads,\n","            dropout,\n","            name=\"encoder\"):\n","  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n","\n","  # 패딩 마스크 사용\n","  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n","\n","  # 임베딩 레이어\n","  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n","  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n","\n","  # 포지셔널 인코딩\n","  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n","\n","  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n","\n","  # num_layers만큼 쌓아올린 인코더의 층.\n","  for i in range(num_layers):\n","    outputs = encoder_layer(\n","        units=units,\n","        d_model=d_model,\n","        num_heads=num_heads,\n","        dropout=dropout,\n","        name=\"encoder_layer_{}\".format(i),\n","    )([outputs, padding_mask])\n","\n","  return tf.keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)"],"metadata":{"id":"C6jiHxDjRTap"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 디코더 하나의 레이어를 함수로 구현.\n","# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n","def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n","  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n","  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n","  look_ahead_mask = tf.keras.Input(\n","      shape=(1, None, None), name=\"look_ahead_mask\")\n","  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n","\n","  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n","  attention1 = MultiHeadAttention(\n","      d_model, num_heads, name=\"attention_1\")(inputs={\n","          'query': inputs,\n","          'key': inputs,\n","          'value': inputs,\n","          'mask': look_ahead_mask\n","      })\n","\n","  # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n","  attention1 = tf.keras.layers.LayerNormalization(\n","      epsilon=1e-6)(attention1 + inputs)\n","\n","  # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n","  attention2 = MultiHeadAttention(\n","      d_model, num_heads, name=\"attention_2\")(inputs={\n","          'query': attention1,\n","          'key': enc_outputs,\n","          'value': enc_outputs,\n","          'mask': padding_mask\n","      })\n","\n","  # 마스크드 멀티 헤드 어텐션의 결과는\n","  # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n","  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n","  attention2 = tf.keras.layers.LayerNormalization(\n","      epsilon=1e-6)(attention2 + attention1)\n","\n","  # 세 번째 서브 레이어 : 2개의 완전연결층\n","  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n","  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n","\n","  # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n","  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n","  outputs = tf.keras.layers.LayerNormalization(\n","      epsilon=1e-6)(outputs + attention2)\n","\n","  return tf.keras.Model(\n","      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n","      outputs=outputs,\n","      name=name)\n","\n","def decoder(vocab_size,\n","            num_layers,\n","            units,\n","            d_model,\n","            num_heads,\n","            dropout,\n","            name='decoder'):\n","  inputs = tf.keras.Input(shape=(None,), name='inputs')\n","  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n","  look_ahead_mask = tf.keras.Input(\n","      shape=(1, None, None), name='look_ahead_mask')\n","\n","  # 패딩 마스크\n","  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n","  \n","  # 임베딩 레이어\n","  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n","  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n","\n","  # 포지셔널 인코딩\n","  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n","\n","  # Dropout이라는 훈련을 돕는 테크닉을 수행\n","  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n","\n","  for i in range(num_layers):\n","    outputs = decoder_layer(\n","        units=units,\n","        d_model=d_model,\n","        num_heads=num_heads,\n","        dropout=dropout,\n","        name='decoder_layer_{}'.format(i),\n","    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n","\n","  return tf.keras.Model(\n","      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n","      outputs=outputs,\n","      name=name)"],"metadata":{"id":"e5R7zIAaRU9Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 사용할 샘플의 최대 개수\n","MAX_SAMPLES = 30000\n","print(MAX_SAMPLES)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OuTj_jTZRW18","executionInfo":{"status":"ok","timestamp":1645497645731,"user_tz":-540,"elapsed":28,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"e8238135-26bd-4363-a1e9-009c35a7f9f6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["30000\n"]}]},{"cell_type":"code","source":["# 전처리 함수\n","def preprocess_sentence(sentence):\n","  sentence = sentence.lower().strip()\n","\n","  # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n","  # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이\n","  # student와 온점 사이에 거리를 만듭니다.\n","  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n","  sentence = re.sub(r'[\" \"]+', \" \", sentence)\n","\n","  # (a-z, A-Z, \".\", \"?\", \"!\", \",\")를 제외한 모든 문자를 공백인 ' '로 대체합니다.\n","#   sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n","  sentence = sentence.strip()\n","  return sentence"],"metadata":{"id":"sWFBJvdJRZbB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 질문과 답변의 쌍인 데이터셋을 구성하기 위한 데이터 로드 함수\n","def load_conversations():\n","    inputs, outputs = [], []\n","    with open(dataset_file_path, 'r') as file:\n","        lines = file.readlines()\n","        \n","    conversation = []\n","    for line in lines[1:]:\n","        parts = line.split(',')\n","        conversation.append([line for line in parts[0:2]])\n","\n","        \n","    for i in range(len(conversation) - 1):\n","        # 전처리 함수를 질문에 해당되는 inputs와 답변에 해당되는 outputs에 적용.\n","        inputs.append(preprocess_sentence(conversation[i][0]))\n","        outputs.append(preprocess_sentence(conversation[i][1]))\n","\n","    if len(inputs) >= MAX_SAMPLES:\n","        return inputs, outputs\n","\n","    return inputs, outputs"],"metadata":{"id":"RdImopmiRdvJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 데이터를 로드하고 전처리하여 질문을 questions, 답변을 answers에 저장합니다.\n","questions, answers = load_conversations()\n","print('전체 샘플 수 :', len(questions))\n","print('전체 샘플 수 :', len(answers))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0eIZQWcdRsdo","executionInfo":{"status":"ok","timestamp":1645497646273,"user_tz":-540,"elapsed":9,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"cdd8fc06-e6f1-46d8-f4c1-a8f08cc5ace3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["전체 샘플 수 : 11822\n","전체 샘플 수 : 11822\n"]}]},{"cell_type":"code","source":["questions[13], answers[22]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KnvDOQ8rRt3h","executionInfo":{"status":"ok","timestamp":1645497646274,"user_tz":-540,"elapsed":9,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"f2a1abba-494e-4f6d-ec87-9a3e6b639413"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('가끔은 혼자인게 좋다', '가장 확실한 시간은 오늘이에요 . 어제와 내일을 놓고 고민하느라 시간을 낭비하지 마세요 .')"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["import tensorflow_datasets as tfds\n","\n","# 질문과 답변 데이터셋에 대해서 Vocabulary 생성. (Tensorflow 2.3.0 이상) (클라우드는 2.4 입니다)\n","tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)"],"metadata":{"id":"zLkCswKYSaWC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n","START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]"],"metadata":{"id":"XENNcGQ2SoNI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n","print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MM2hu7OgSpgm","executionInfo":{"status":"ok","timestamp":1645497661855,"user_tz":-540,"elapsed":199,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"70cdbafb-f023-4ce1-9cfb-7ab34385b475"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["START_TOKEN의 번호 : [8149]\n","END_TOKEN의 번호 : [8150]\n"]}]},{"cell_type":"code","source":["# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n","VOCAB_SIZE = tokenizer.vocab_size + 2\n","print(VOCAB_SIZE)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TzKQ_6rlSqlG","executionInfo":{"status":"ok","timestamp":1645497661856,"user_tz":-540,"elapsed":73,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"91093f9c-c11a-4de0-ea2b-f20ee9e0d64b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["8151\n"]}]},{"cell_type":"code","source":["# 임의의 22번째 샘플에 대해서 정수 인코딩 작업을 수행.\n","# 각 토큰을 고유한 정수로 변환\n","print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(questions[22])))\n","print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(answers[22])))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ac55EtvwSrx-","executionInfo":{"status":"ok","timestamp":1645497661856,"user_tz":-540,"elapsed":33,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"fe2964f5-7bf7-4b27-ca32-38686241fc17"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["정수 인코딩 후의 21번째 질문 샘플: [387, 809, 43, 410, 2]\n","정수 인코딩 후의 21번째 답변 샘플: [387, 809, 912, 6515, 12, 5068, 7579, 1107, 7764, 355, 5575, 44, 1]\n"]}]},{"cell_type":"code","source":["# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n","MAX_LENGTH = 40\n","print(MAX_LENGTH)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BnmjcGkZStS3","executionInfo":{"status":"ok","timestamp":1645497661857,"user_tz":-540,"elapsed":28,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"96832b89-c3b8-4ae5-a8a8-53019820e250"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["40\n"]}]},{"cell_type":"code","source":["# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n","def tokenize_and_filter(inputs, outputs):\n","  tokenized_inputs, tokenized_outputs = [], []\n","  \n","  for (sentence1, sentence2) in zip(inputs, outputs):\n","    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n","    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n","    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n","\n","    # 최대 길이 40 이하인 경우에만 데이터셋으로 허용\n","    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n","      tokenized_inputs.append(sentence1)\n","      tokenized_outputs.append(sentence2)\n","  \n","  # 최대 길이 40으로 모든 데이터셋을 패딩\n","  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n","      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n","  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n","      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n","  \n","  return tokenized_inputs, tokenized_outputs"],"metadata":{"id":"OrbNJhRfSuIj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["questions, answers = tokenize_and_filter(questions, answers)\n","print('단어장의 크기 :',(VOCAB_SIZE))\n","print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n","print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ac_9uDczSvZQ","executionInfo":{"status":"ok","timestamp":1645497662243,"user_tz":-540,"elapsed":406,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"f2299d41-e2e6-483a-8669-0310e22dbfc1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["단어장의 크기 : 8151\n","필터링 후의 질문 샘플 개수: 11822\n","필터링 후의 답변 샘플 개수: 11822\n"]}]},{"cell_type":"code","source":["BATCH_SIZE = 64\n","BUFFER_SIZE = 20000\n","\n","# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n","# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n","dataset = tf.data.Dataset.from_tensor_slices((\n","    {\n","        'inputs': questions,\n","        'dec_inputs': answers[:, :-1]\n","    },\n","    {\n","        'outputs': answers[:, 1:]\n","    },\n","))\n","\n","dataset = dataset.cache()\n","dataset = dataset.shuffle(BUFFER_SIZE)\n","dataset = dataset.batch(BATCH_SIZE)\n","dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"],"metadata":{"id":"rNZ3Mks1Swtz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def transformer(vocab_size,\n","                num_layers,\n","                units,\n","                d_model,\n","                num_heads,\n","                dropout,\n","                name=\"transformer\"):\n","  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n","  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n","\n","  # 인코더에서 패딩을 위한 마스크\n","  enc_padding_mask = tf.keras.layers.Lambda(\n","      create_padding_mask, output_shape=(1, 1, None),\n","      name='enc_padding_mask')(inputs)\n","\n","  # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n","  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n","  look_ahead_mask = tf.keras.layers.Lambda(\n","      create_look_ahead_mask,\n","      output_shape=(1, None, None),\n","      name='look_ahead_mask')(dec_inputs)\n","\n","  # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n","  # 디코더에서 패딩을 위한 마스크\n","  dec_padding_mask = tf.keras.layers.Lambda(\n","      create_padding_mask, output_shape=(1, 1, None),\n","      name='dec_padding_mask')(inputs)\n","\n","  # 인코더\n","  enc_outputs = encoder(\n","      vocab_size=vocab_size,\n","      num_layers=num_layers,\n","      units=units,\n","      d_model=d_model,\n","      num_heads=num_heads,\n","      dropout=dropout,\n","  )(inputs=[inputs, enc_padding_mask])\n","\n","  # 디코더\n","  dec_outputs = decoder(\n","      vocab_size=vocab_size,\n","      num_layers=num_layers,\n","      units=units,\n","      d_model=d_model,\n","      num_heads=num_heads,\n","      dropout=dropout,\n","  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n","\n","  # 완전연결층\n","  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n","\n","  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"],"metadata":{"id":"t-NJNwEiS5iY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tf.keras.backend.clear_session()\n","\n","# 하이퍼파라미터\n","NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n","D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n","NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n","UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n","DROPOUT = 0.1 # 드롭아웃의 비율\n","\n","model = transformer(\n","    vocab_size=VOCAB_SIZE,\n","    num_layers=NUM_LAYERS,\n","    units=UNITS,\n","    d_model=D_MODEL,\n","    num_heads=NUM_HEADS,\n","    dropout=DROPOUT)\n","\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jp3z10UrS7Mv","executionInfo":{"status":"ok","timestamp":1645497668050,"user_tz":-540,"elapsed":3421,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"2604ee5e-6415-42c5-9a27-258bcd8b66c2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"transformer\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," inputs (InputLayer)            [(None, None)]       0           []                               \n","                                                                                                  \n"," dec_inputs (InputLayer)        [(None, None)]       0           []                               \n","                                                                                                  \n"," enc_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n","                                                                                                  \n"," encoder (Functional)           (None, None, 256)    3140864     ['inputs[0][0]',                 \n","                                                                  'enc_padding_mask[0][0]']       \n","                                                                                                  \n"," look_ahead_mask (Lambda)       (None, 1, None, Non  0           ['dec_inputs[0][0]']             \n","                                e)                                                                \n","                                                                                                  \n"," dec_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n","                                                                                                  \n"," decoder (Functional)           (None, None, 256)    3668224     ['dec_inputs[0][0]',             \n","                                                                  'encoder[0][0]',                \n","                                                                  'look_ahead_mask[0][0]',        \n","                                                                  'dec_padding_mask[0][0]']       \n","                                                                                                  \n"," outputs (Dense)                (None, None, 8151)   2094807     ['decoder[0][0]']                \n","                                                                                                  \n","==================================================================================================\n","Total params: 8,903,895\n","Trainable params: 8,903,895\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["def loss_function(y_true, y_pred):\n","  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n","  \n","  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n","      from_logits=True, reduction='none')(y_true, y_pred)\n","\n","  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n","  loss = tf.multiply(loss, mask)\n","\n","  return tf.reduce_mean(loss)"],"metadata":{"id":"-H_KwvHZS8Z6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n","    def __init__(self, d_model, warmup_steps=4000):\n","        super(CustomSchedule, self).__init__()\n","\n","        self.d_model = d_model\n","        self.d_model = tf.cast(self.d_model, tf.float32)\n","\n","        self.warmup_steps = warmup_steps\n","\n","    def __call__(self, step):\n","        arg1 = tf.math.rsqrt(step)\n","        arg2 = step * (self.warmup_steps**-1.5)\n","\n","        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"],"metadata":{"id":"udCd3wNMT2Ys"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sample_learning_rate = CustomSchedule(d_model=128)\n","\n","plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n","plt.ylabel(\"Learning Rate\")\n","plt.xlabel(\"Train Step\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":297},"id":"tUZuiUxrS-I4","executionInfo":{"status":"ok","timestamp":1645497780294,"user_tz":-540,"elapsed":473,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"c11c3ba0-20da-4bd2-84ab-385dd1e55554"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Text(0.5, 0, 'Train Step')"]},"metadata":{},"execution_count":49},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["learning_rate = CustomSchedule(D_MODEL)\n","\n","optimizer = tf.keras.optimizers.Adam(\n","    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n","\n","def accuracy(y_true, y_pred):\n","  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n","  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n","\n","model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"],"metadata":{"id":"pm5Lr8ucS_OV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["EPOCHS = 20\n","model.fit(dataset, epochs=EPOCHS, verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tChEmV26TAiv","executionInfo":{"status":"ok","timestamp":1645497999967,"user_tz":-540,"elapsed":214403,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"82ea7413-73f5-4b88-9bf7-66f9f23a6c70"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","185/185 [==============================] - 19s 55ms/step - loss: 1.4384 - accuracy: 0.0245\n","Epoch 2/20\n","185/185 [==============================] - 10s 53ms/step - loss: 1.1713 - accuracy: 0.0487\n","Epoch 3/20\n","185/185 [==============================] - 10s 53ms/step - loss: 0.9983 - accuracy: 0.0501\n","Epoch 4/20\n","185/185 [==============================] - 10s 54ms/step - loss: 0.9232 - accuracy: 0.0537\n","Epoch 5/20\n","185/185 [==============================] - 10s 54ms/step - loss: 0.8668 - accuracy: 0.0572\n","Epoch 6/20\n","185/185 [==============================] - 10s 54ms/step - loss: 0.8075 - accuracy: 0.0615\n","Epoch 7/20\n","185/185 [==============================] - 10s 55ms/step - loss: 0.7407 - accuracy: 0.0677\n","Epoch 8/20\n","185/185 [==============================] - 10s 55ms/step - loss: 0.6676 - accuracy: 0.0753\n","Epoch 9/20\n","185/185 [==============================] - 10s 55ms/step - loss: 0.5887 - accuracy: 0.0839\n","Epoch 10/20\n","185/185 [==============================] - 10s 56ms/step - loss: 0.5067 - accuracy: 0.0932\n","Epoch 11/20\n","185/185 [==============================] - 10s 56ms/step - loss: 0.4243 - accuracy: 0.1035\n","Epoch 12/20\n","185/185 [==============================] - 10s 56ms/step - loss: 0.3438 - accuracy: 0.1146\n","Epoch 13/20\n","185/185 [==============================] - 10s 56ms/step - loss: 0.2704 - accuracy: 0.1253\n","Epoch 14/20\n","185/185 [==============================] - 10s 56ms/step - loss: 0.2052 - accuracy: 0.1355\n","Epoch 15/20\n","185/185 [==============================] - 10s 56ms/step - loss: 0.1516 - accuracy: 0.1447\n","Epoch 16/20\n","185/185 [==============================] - 10s 56ms/step - loss: 0.1104 - accuracy: 0.1521\n","Epoch 17/20\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0801 - accuracy: 0.1576\n","Epoch 18/20\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0612 - accuracy: 0.1612\n","Epoch 19/20\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0510 - accuracy: 0.1627\n","Epoch 20/20\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0448 - accuracy: 0.1637\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f1dd75f71d0>"]},"metadata":{},"execution_count":51}]},{"cell_type":"code","source":["def decoder_inference(sentence):\n","  sentence = preprocess_sentence(sentence)\n","\n","  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n","  # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n","  sentence = tf.expand_dims(\n","      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n","\n","  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n","  # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n","  output_sequence = tf.expand_dims(START_TOKEN, 0)\n","\n","  # 디코더의 인퍼런스 단계\n","  for i in range(MAX_LENGTH):\n","    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n","    predictions = model(inputs=[sentence, output_sequence], training=False)\n","    predictions = predictions[:, -1:, :]\n","\n","    # 현재 예측한 단어의 정수\n","    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n","\n","    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n","    if tf.equal(predicted_id, END_TOKEN[0]):\n","      break\n","\n","    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n","    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n","    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n","\n","  return tf.squeeze(output_sequence, axis=0)"],"metadata":{"id":"theBHchETBuA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def sentence_generation(sentence):\n","  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n","  prediction = decoder_inference(sentence)\n","\n","  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n","  predicted_sentence = tokenizer.decode(\n","      [i for i in prediction if i < tokenizer.vocab_size])\n","\n","  print('입력 : {}'.format(sentence))\n","  print('출력 : {}'.format(predicted_sentence))\n","\n","  return predicted_sentence"],"metadata":{"id":"Fj6EWkRrTDS9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sentence_generation('집에 가고 싶다')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"OWDdQZYTTEcC","executionInfo":{"status":"ok","timestamp":1645497999974,"user_tz":-540,"elapsed":48,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"36feb8d0-1558-4a2e-b19a-474d4678fd63"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["입력 : 집에 가고 싶다\n","출력 : 집이 최고죠 .\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'집이 최고죠 .'"]},"metadata":{},"execution_count":54}]},{"cell_type":"code","source":["sentence_generation('햇볕은 쨍쨍')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"mAtXSNycTIXd","executionInfo":{"status":"ok","timestamp":1645498000530,"user_tz":-540,"elapsed":571,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"1eac18c6-1d1b-4522-8653-a154afe414c6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["입력 : 햇볕은 쨍쨍\n","출력 : 덜 부담스럽게 연락하는 방법이 있는지 모르겠네요 .\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'덜 부담스럽게 연락하는 방법이 있는지 모르겠네요 .'"]},"metadata":{},"execution_count":55}]},{"cell_type":"code","source":["sentence_generation('좋은 하루')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"Swlr36uMTMhI","executionInfo":{"status":"ok","timestamp":1645498000994,"user_tz":-540,"elapsed":478,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"2f7045d4-fdaf-41f3-8400-73733aa33805"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["입력 : 좋은 하루\n","출력 : 내일도 좋은 하루 보내세요 .\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'내일도 좋은 하루 보내세요 .'"]},"metadata":{},"execution_count":56}]},{"cell_type":"code","source":["sentence_generation('여기는 어디')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"34XjEo8STODR","executionInfo":{"status":"ok","timestamp":1645498000994,"user_tz":-540,"elapsed":72,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"9c674bb4-9ca2-4b3a-80dd-594f8648aa9e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["입력 : 여기는 어디\n","출력 : 퍼가요~\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'퍼가요~'"]},"metadata":{},"execution_count":57}]},{"cell_type":"code","source":["sentence_generation('핸드폰')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"FZduMMSNTQhf","executionInfo":{"status":"ok","timestamp":1645498001871,"user_tz":-540,"elapsed":945,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"612bd504-d1b9-4dd3-d510-8a1d209eff60"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["입력 : 핸드폰\n","출력 : 기억에서 지울 순 없지만 최대한 생각 말아보셔요 .\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'기억에서 지울 순 없지만 최대한 생각 말아보셔요 .'"]},"metadata":{},"execution_count":58}]},{"cell_type":"code","source":["sentence_generation('너 봤구나')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"8rptdaODT76i","executionInfo":{"status":"ok","timestamp":1645498042370,"user_tz":-540,"elapsed":1492,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"de88fa10-8319-479e-9192-5a8efee91345"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["입력 : 너 봤구나\n","출력 : 아직 힘들시기에요 .\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'아직 힘들시기에요 .'"]},"metadata":{},"execution_count":59}]},{"cell_type":"code","source":["sentence_generation('졸려 죽겠어')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"8EduaHIwU36R","executionInfo":{"status":"ok","timestamp":1645498557922,"user_tz":-540,"elapsed":1016,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"59d9f9c0-b81a-4f6c-8949-27d3e8722b5e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["입력 : 졸려 죽겠어\n","출력 : 오늘 일찍 주무세요 .\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'오늘 일찍 주무세요 .'"]},"metadata":{},"execution_count":60}]},{"cell_type":"code","source":["sentence_generation('주말이 언제 올까?')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"QwOLKCWjW14y","executionInfo":{"status":"ok","timestamp":1645498571976,"user_tz":-540,"elapsed":445,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"1e14e86c-1bdc-426d-801c-2f6b175be4aa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["입력 : 주말이 언제 올까?\n","출력 : 천천히 보내주세요 .\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'천천히 보내주세요 .'"]},"metadata":{},"execution_count":61}]},{"cell_type":"code","source":["sentence_generation('피곤해')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"Y9SV5YkqW5ci","executionInfo":{"status":"ok","timestamp":1645498588659,"user_tz":-540,"elapsed":908,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"ea6ceb0d-275f-4744-8eac-476239eec7c9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["입력 : 피곤해\n","출력 : 좀 더 일찍 잠자리에 들어보세요 .\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'좀 더 일찍 잠자리에 들어보세요 .'"]},"metadata":{},"execution_count":62}]},{"cell_type":"markdown","source":["### 베이스라인 결과  \n","----  \n","꽤나 말을 잘하는 녀석이 만들어졌다. 집이 최고라는 걸 아는 이 녀석은 아주 잘 배운녀석이라고 생각하지만, 몇 몇 단어들에 대한 출력물은 대화라고 할 수 없는 수준으로 보인다. 데이터셋을 더 늘리는 방법을 사용한다면 좋겠지만 여기에서는 그런 방법을 사용하기에는 힘드니 epoch를 더 늘려보기로 결정했다."],"metadata":{"id":"Of6sO7ujxsYK"}},{"cell_type":"code","source":["learning_rate = CustomSchedule(D_MODEL)\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n","\n","def accuracy(y_true, y_pred):\n","    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n","    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n","\n","model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"],"metadata":{"id":"cRGHtIYFW9hr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["EPOCHS = 200\n","model.fit(dataset, epochs=EPOCHS, verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wa8M4jP1XIMA","executionInfo":{"status":"ok","timestamp":1645500761550,"user_tz":-540,"elapsed":2104717,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"43deb628-365b-49f4-84f7-c1ce96a8c44c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","185/185 [==============================] - 16s 55ms/step - loss: 0.0252 - accuracy: 0.1684\n","Epoch 2/200\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0163 - accuracy: 0.1706\n","Epoch 3/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0103 - accuracy: 0.1722\n","Epoch 4/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0071 - accuracy: 0.1729\n","Epoch 5/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0063 - accuracy: 0.1730\n","Epoch 6/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0064 - accuracy: 0.1729\n","Epoch 7/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0066 - accuracy: 0.1729\n","Epoch 8/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0068 - accuracy: 0.1728\n","Epoch 9/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0074 - accuracy: 0.1726\n","Epoch 10/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0079 - accuracy: 0.1725\n","Epoch 11/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0086 - accuracy: 0.1723\n","Epoch 12/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0096 - accuracy: 0.1721\n","Epoch 13/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0109 - accuracy: 0.1717\n","Epoch 14/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0115 - accuracy: 0.1716\n","Epoch 15/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0130 - accuracy: 0.1712\n","Epoch 16/200\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0138 - accuracy: 0.1710\n","Epoch 17/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0150 - accuracy: 0.1706\n","Epoch 18/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0159 - accuracy: 0.1702\n","Epoch 19/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0177 - accuracy: 0.1699\n","Epoch 20/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0184 - accuracy: 0.1696\n","Epoch 21/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0210 - accuracy: 0.1690\n","Epoch 22/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0211 - accuracy: 0.1689\n","Epoch 23/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0207 - accuracy: 0.1691\n","Epoch 24/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0192 - accuracy: 0.1693\n","Epoch 25/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0176 - accuracy: 0.1698\n","Epoch 26/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0163 - accuracy: 0.1702\n","Epoch 27/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0146 - accuracy: 0.1705\n","Epoch 28/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0142 - accuracy: 0.1705\n","Epoch 29/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0132 - accuracy: 0.1710\n","Epoch 30/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0122 - accuracy: 0.1712\n","Epoch 31/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0115 - accuracy: 0.1714\n","Epoch 32/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0108 - accuracy: 0.1715\n","Epoch 33/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0102 - accuracy: 0.1717\n","Epoch 34/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0099 - accuracy: 0.1718\n","Epoch 35/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0087 - accuracy: 0.1722\n","Epoch 36/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0089 - accuracy: 0.1721\n","Epoch 37/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0083 - accuracy: 0.1722\n","Epoch 38/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0079 - accuracy: 0.1723\n","Epoch 39/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0077 - accuracy: 0.1724\n","Epoch 40/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0070 - accuracy: 0.1725\n","Epoch 41/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0068 - accuracy: 0.1726\n","Epoch 42/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0067 - accuracy: 0.1726\n","Epoch 43/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0066 - accuracy: 0.1726\n","Epoch 44/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0063 - accuracy: 0.1727\n","Epoch 45/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0060 - accuracy: 0.1728\n","Epoch 46/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0058 - accuracy: 0.1728\n","Epoch 47/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0058 - accuracy: 0.1728\n","Epoch 48/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0055 - accuracy: 0.1729\n","Epoch 49/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0051 - accuracy: 0.1730\n","Epoch 50/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0049 - accuracy: 0.1730\n","Epoch 51/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0047 - accuracy: 0.1730\n","Epoch 52/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0044 - accuracy: 0.1732\n","Epoch 53/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0048 - accuracy: 0.1731\n","Epoch 54/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0043 - accuracy: 0.1731\n","Epoch 55/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0044 - accuracy: 0.1732\n","Epoch 56/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0041 - accuracy: 0.1732\n","Epoch 57/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0040 - accuracy: 0.1732\n","Epoch 58/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0040 - accuracy: 0.1732\n","Epoch 59/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0038 - accuracy: 0.1733\n","Epoch 60/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0040 - accuracy: 0.1732\n","Epoch 61/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0037 - accuracy: 0.1733\n","Epoch 62/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0036 - accuracy: 0.1733\n","Epoch 63/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0036 - accuracy: 0.1733\n","Epoch 64/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0037 - accuracy: 0.1733\n","Epoch 65/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0031 - accuracy: 0.1734\n","Epoch 66/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0037 - accuracy: 0.1732\n","Epoch 67/200\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0034 - accuracy: 0.1733\n","Epoch 68/200\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0033 - accuracy: 0.1734\n","Epoch 69/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0031 - accuracy: 0.1734\n","Epoch 70/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0033 - accuracy: 0.1733\n","Epoch 71/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0030 - accuracy: 0.1734\n","Epoch 72/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0030 - accuracy: 0.1734\n","Epoch 73/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0029 - accuracy: 0.1734\n","Epoch 74/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0027 - accuracy: 0.1735\n","Epoch 75/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0030 - accuracy: 0.1734\n","Epoch 76/200\n","185/185 [==============================] - 11s 57ms/step - loss: 0.0026 - accuracy: 0.1735\n","Epoch 77/200\n","185/185 [==============================] - 11s 57ms/step - loss: 0.0028 - accuracy: 0.1735\n","Epoch 78/200\n","185/185 [==============================] - 11s 59ms/step - loss: 0.0026 - accuracy: 0.1735\n","Epoch 79/200\n","185/185 [==============================] - 11s 57ms/step - loss: 0.0027 - accuracy: 0.1735\n","Epoch 80/200\n","185/185 [==============================] - 11s 57ms/step - loss: 0.0024 - accuracy: 0.1735\n","Epoch 81/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0025 - accuracy: 0.1735\n","Epoch 82/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0024 - accuracy: 0.1735\n","Epoch 83/200\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0024 - accuracy: 0.1735\n","Epoch 84/200\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0023 - accuracy: 0.1735\n","Epoch 85/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0023 - accuracy: 0.1735\n","Epoch 86/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0022 - accuracy: 0.1735\n","Epoch 87/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0021 - accuracy: 0.1735\n","Epoch 88/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0022 - accuracy: 0.1735\n","Epoch 89/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0022 - accuracy: 0.1735\n","Epoch 90/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0021 - accuracy: 0.1735\n","Epoch 91/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0019 - accuracy: 0.1736\n","Epoch 92/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0021 - accuracy: 0.1735\n","Epoch 93/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0019 - accuracy: 0.1736\n","Epoch 94/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0020 - accuracy: 0.1735\n","Epoch 95/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0022 - accuracy: 0.1735\n","Epoch 96/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0019 - accuracy: 0.1736\n","Epoch 97/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0020 - accuracy: 0.1735\n","Epoch 98/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0018 - accuracy: 0.1736\n","Epoch 99/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0019 - accuracy: 0.1735\n","Epoch 100/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0018 - accuracy: 0.1735\n","Epoch 101/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0017 - accuracy: 0.1736\n","Epoch 102/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0017 - accuracy: 0.1736\n","Epoch 103/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0016 - accuracy: 0.1736\n","Epoch 104/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0016 - accuracy: 0.1736\n","Epoch 105/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0018 - accuracy: 0.1736\n","Epoch 106/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0016 - accuracy: 0.1736\n","Epoch 107/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0016 - accuracy: 0.1736\n","Epoch 108/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0017 - accuracy: 0.1736\n","Epoch 109/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0016 - accuracy: 0.1736\n","Epoch 110/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0017 - accuracy: 0.1736\n","Epoch 111/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0017 - accuracy: 0.1736\n","Epoch 112/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0014 - accuracy: 0.1736\n","Epoch 113/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0016 - accuracy: 0.1736\n","Epoch 114/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0014 - accuracy: 0.1736\n","Epoch 115/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0015 - accuracy: 0.1736\n","Epoch 116/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0016 - accuracy: 0.1736\n","Epoch 117/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0016 - accuracy: 0.1736\n","Epoch 118/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0015 - accuracy: 0.1736\n","Epoch 119/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0017 - accuracy: 0.1736\n","Epoch 120/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0016 - accuracy: 0.1736\n","Epoch 121/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0015 - accuracy: 0.1736\n","Epoch 122/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0015 - accuracy: 0.1736\n","Epoch 123/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0014 - accuracy: 0.1736\n","Epoch 124/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0015 - accuracy: 0.1736\n","Epoch 125/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0015 - accuracy: 0.1736\n","Epoch 126/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0013 - accuracy: 0.1737\n","Epoch 127/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0014 - accuracy: 0.1736\n","Epoch 128/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0012 - accuracy: 0.1737\n","Epoch 129/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0012 - accuracy: 0.1737\n","Epoch 130/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0013 - accuracy: 0.1736\n","Epoch 131/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0012 - accuracy: 0.1736\n","Epoch 132/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0012 - accuracy: 0.1737\n","Epoch 133/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0013 - accuracy: 0.1737\n","Epoch 134/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0013 - accuracy: 0.1736\n","Epoch 135/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0014 - accuracy: 0.1736\n","Epoch 136/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0012 - accuracy: 0.1736\n","Epoch 137/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0013 - accuracy: 0.1736\n","Epoch 138/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0012 - accuracy: 0.1736\n","Epoch 139/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0012 - accuracy: 0.1737\n","Epoch 140/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0012 - accuracy: 0.1736\n","Epoch 141/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0012 - accuracy: 0.1736\n","Epoch 142/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0014 - accuracy: 0.1736\n","Epoch 143/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0011 - accuracy: 0.1737\n","Epoch 144/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0013 - accuracy: 0.1736\n","Epoch 145/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0013 - accuracy: 0.1736\n","Epoch 146/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0012 - accuracy: 0.1736\n","Epoch 147/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0011 - accuracy: 0.1736\n","Epoch 148/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0012 - accuracy: 0.1737\n","Epoch 149/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0012 - accuracy: 0.1737\n","Epoch 150/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0012 - accuracy: 0.1736\n","Epoch 151/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0011 - accuracy: 0.1737\n","Epoch 152/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0013 - accuracy: 0.1736\n","Epoch 153/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0011 - accuracy: 0.1737\n","Epoch 154/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0010 - accuracy: 0.1737\n","Epoch 155/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0011 - accuracy: 0.1737\n","Epoch 156/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0011 - accuracy: 0.1737\n","Epoch 157/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0012 - accuracy: 0.1736\n","Epoch 158/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0013 - accuracy: 0.1737\n","Epoch 159/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0012 - accuracy: 0.1737\n","Epoch 160/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0012 - accuracy: 0.1737\n","Epoch 161/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0011 - accuracy: 0.1737\n","Epoch 162/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0012 - accuracy: 0.1736\n","Epoch 163/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0011 - accuracy: 0.1736\n","Epoch 164/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0012 - accuracy: 0.1736\n","Epoch 165/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0011 - accuracy: 0.1737\n","Epoch 166/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0011 - accuracy: 0.1736\n","Epoch 167/200\n","185/185 [==============================] - 10s 56ms/step - loss: 9.6922e-04 - accuracy: 0.1737\n","Epoch 168/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0011 - accuracy: 0.1737\n","Epoch 169/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0010 - accuracy: 0.1737\n","Epoch 170/200\n","185/185 [==============================] - 10s 56ms/step - loss: 9.4672e-04 - accuracy: 0.1737\n","Epoch 171/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0010 - accuracy: 0.1737\n","Epoch 172/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0011 - accuracy: 0.1736\n","Epoch 173/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0012 - accuracy: 0.1736\n","Epoch 174/200\n","185/185 [==============================] - 10s 56ms/step - loss: 9.0012e-04 - accuracy: 0.1737\n","Epoch 175/200\n","185/185 [==============================] - 10s 57ms/step - loss: 0.0010 - accuracy: 0.1737\n","Epoch 176/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0011 - accuracy: 0.1737\n","Epoch 177/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0010 - accuracy: 0.1736\n","Epoch 178/200\n","185/185 [==============================] - 10s 55ms/step - loss: 9.1907e-04 - accuracy: 0.1737\n","Epoch 179/200\n","185/185 [==============================] - 10s 56ms/step - loss: 8.7177e-04 - accuracy: 0.1737\n","Epoch 180/200\n","185/185 [==============================] - 10s 56ms/step - loss: 8.4071e-04 - accuracy: 0.1737\n","Epoch 181/200\n","185/185 [==============================] - 10s 56ms/step - loss: 9.8347e-04 - accuracy: 0.1737\n","Epoch 182/200\n","185/185 [==============================] - 10s 56ms/step - loss: 9.9423e-04 - accuracy: 0.1737\n","Epoch 183/200\n","185/185 [==============================] - 10s 56ms/step - loss: 9.5718e-04 - accuracy: 0.1737\n","Epoch 184/200\n","185/185 [==============================] - 10s 56ms/step - loss: 9.6731e-04 - accuracy: 0.1736\n","Epoch 185/200\n","185/185 [==============================] - 10s 56ms/step - loss: 8.9855e-04 - accuracy: 0.1737\n","Epoch 186/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0011 - accuracy: 0.1737\n","Epoch 187/200\n","185/185 [==============================] - 10s 56ms/step - loss: 9.4521e-04 - accuracy: 0.1737\n","Epoch 188/200\n","185/185 [==============================] - 10s 56ms/step - loss: 8.8582e-04 - accuracy: 0.1737\n","Epoch 189/200\n","185/185 [==============================] - 10s 56ms/step - loss: 9.6138e-04 - accuracy: 0.1737\n","Epoch 190/200\n","185/185 [==============================] - 10s 56ms/step - loss: 9.2518e-04 - accuracy: 0.1737\n","Epoch 191/200\n","185/185 [==============================] - 10s 56ms/step - loss: 9.6574e-04 - accuracy: 0.1737\n","Epoch 192/200\n","185/185 [==============================] - 10s 56ms/step - loss: 9.9091e-04 - accuracy: 0.1737\n","Epoch 193/200\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0010 - accuracy: 0.1737\n","Epoch 194/200\n","185/185 [==============================] - 10s 56ms/step - loss: 8.8479e-04 - accuracy: 0.1737\n","Epoch 195/200\n","185/185 [==============================] - 10s 56ms/step - loss: 9.2920e-04 - accuracy: 0.1737\n","Epoch 196/200\n","185/185 [==============================] - 10s 56ms/step - loss: 9.4287e-04 - accuracy: 0.1737\n","Epoch 197/200\n","185/185 [==============================] - 10s 56ms/step - loss: 9.6723e-04 - accuracy: 0.1737\n","Epoch 198/200\n","185/185 [==============================] - 10s 56ms/step - loss: 9.6431e-04 - accuracy: 0.1736\n","Epoch 199/200\n","185/185 [==============================] - 10s 56ms/step - loss: 9.8385e-04 - accuracy: 0.1737\n","Epoch 200/200\n","185/185 [==============================] - 10s 56ms/step - loss: 9.6149e-04 - accuracy: 0.1737\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f1d5a2ea210>"]},"metadata":{},"execution_count":64}]},{"cell_type":"code","source":["sentence_generation('집에 가고 싶다')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"kpp5yx1XXOSq","executionInfo":{"status":"ok","timestamp":1645500773063,"user_tz":-540,"elapsed":560,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"67fa40e8-e5dc-48bc-a916-d2c6e9dc6329"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["입력 : 집에 가고 싶다\n","출력 : 집이 최고죠 .\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'집이 최고죠 .'"]},"metadata":{},"execution_count":65}]},{"cell_type":"code","source":["sentence_generation('햇볕은 쨍쨍')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"1uhqVLrZaPNm","executionInfo":{"status":"ok","timestamp":1645500773489,"user_tz":-540,"elapsed":11,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"048b8521-c360-4603-925a-c3d90bd57142"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["입력 : 햇볕은 쨍쨍\n","출력 : 광합성 추천합니다 .\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'광합성 추천합니다 .'"]},"metadata":{},"execution_count":66}]},{"cell_type":"code","source":["sentence_generation('좋은 하루')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"DXZ1PrPoaSA6","executionInfo":{"status":"ok","timestamp":1645500774317,"user_tz":-540,"elapsed":836,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"799b01e3-e895-4028-8d89-0bc80c2709ea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["입력 : 좋은 하루\n","출력 : 내일도 좋은 하루 보내세요 .\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'내일도 좋은 하루 보내세요 .'"]},"metadata":{},"execution_count":67}]},{"cell_type":"code","source":["sentence_generation('여기는 어디')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"chlV736PaVIO","executionInfo":{"status":"ok","timestamp":1645500774727,"user_tz":-540,"elapsed":427,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"9200d967-a356-45e8-d163-6e17f5acd0f2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["입력 : 여기는 어디\n","출력 : 소리를 크게한번 질러보세요 .\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'소리를 크게한번 질러보세요 .'"]},"metadata":{},"execution_count":68}]},{"cell_type":"code","source":["sentence_generation('핸드폰')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"IqjdoFOXaYdV","executionInfo":{"status":"ok","timestamp":1645500775744,"user_tz":-540,"elapsed":1021,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"d733e703-b45c-401a-d1f5-9f87e342142a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["입력 : 핸드폰\n","출력 : 시간을 정해보세요 .\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'시간을 정해보세요 .'"]},"metadata":{},"execution_count":69}]},{"cell_type":"code","source":["sentence_generation('너 봤구나')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"YXTYR2gcfTIj","executionInfo":{"status":"ok","timestamp":1645500803305,"user_tz":-540,"elapsed":929,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"ff355849-ccc5-4d43-9be9-e2fa2f0d1030"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["입력 : 너 봤구나\n","출력 : 여전하던가요 ?\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'여전하던가요 ?'"]},"metadata":{},"execution_count":70}]},{"cell_type":"code","source":["sentence_generation('졸려 죽겠어')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"2QnWfzKWfaGf","executionInfo":{"status":"ok","timestamp":1645500823578,"user_tz":-540,"elapsed":964,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"1e88a240-822d-4fb5-c2bf-7eb1e33ab560"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["입력 : 졸려 죽겠어\n","출력 : 바람이라도 쐬고 오는 건 어떨까요 .\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'바람이라도 쐬고 오는 건 어떨까요 .'"]},"metadata":{},"execution_count":71}]},{"cell_type":"code","source":["sentence_generation('주말이 언제 올까?')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"SJPU05btffJT","executionInfo":{"status":"ok","timestamp":1645500835494,"user_tz":-540,"elapsed":980,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"075e3d27-78f3-4653-8f28-a05c72e730b5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["입력 : 주말이 언제 올까?\n","출력 : 자신에게 시간을 더 주세요 .\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'자신에게 시간을 더 주세요 .'"]},"metadata":{},"execution_count":72}]},{"cell_type":"code","source":["sentence_generation('피곤해')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"gzVv94PAfiDC","executionInfo":{"status":"ok","timestamp":1645500846268,"user_tz":-540,"elapsed":421,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"28576719-53d1-4dca-d3b3-0cef68ab9b78"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["입력 : 피곤해\n","출력 : 푹 쉬세요 .\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'푹 쉬세요 .'"]},"metadata":{},"execution_count":73}]},{"cell_type":"markdown","source":["#### 중간 회고  \n","----  \n","이번엔 epoch를 200으로 늘려보았더니 확실히 똑똑해진 모습을 보여줬다. 아무래도 언더피팅 상태였나보다. 몇 가지 단어를 더 입력해보면 어땠을까하는 아쉬움이 남지만 이 당시에는 급급했기에 어쩔 수 없었다. 특히 햇볕은 쨍쨍이라는 말에 대한 답이 꽤나 만족스럽다. 광합성을 아는 녀석이라니 잘 배운 녀석이 틀림없다. 그리고 너 봤구나라는 입력에 대한 답변 또한 기존의 모델에서 많이 달라진 모습을 보이고 의미가 연결되는 답변을 내놓았다. 이 두가지가 굉장히 흡족하였다. 하지만 핸드폰이란 입력은 입력자체가 난해해서 그런지 매번 답변을 제대로 해내지 못하는 모습이다. 아무래도 입력단어에 대한 유추가 불가능한 것 같다. "],"metadata":{"id":"6c7APHB1yYaf"}},{"cell_type":"code","source":["learning_rate = CustomSchedule(D_MODEL)\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n","\n","def accuracy(y_true, y_pred):\n","    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n","    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n","\n","model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"],"metadata":{"id":"k-lZfROjfkte"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["EPOCHS = 400\n","model.fit(dataset, epochs=EPOCHS, verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"inDRlqkcfn8-","executionInfo":{"status":"ok","timestamp":1645505085946,"user_tz":-540,"elapsed":4209450,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"ddb17d18-8f7e-4c84-be40-0cb959d5ccb9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/400\n","185/185 [==============================] - 16s 55ms/step - loss: 5.5595e-04 - accuracy: 0.1738\n","Epoch 2/400\n","185/185 [==============================] - 10s 56ms/step - loss: 5.2742e-04 - accuracy: 0.1738\n","Epoch 3/400\n","185/185 [==============================] - 10s 56ms/step - loss: 5.2608e-04 - accuracy: 0.1738\n","Epoch 4/400\n","185/185 [==============================] - 10s 57ms/step - loss: 5.4736e-04 - accuracy: 0.1737\n","Epoch 5/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.2117e-04 - accuracy: 0.1737\n","Epoch 6/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.6775e-04 - accuracy: 0.1737\n","Epoch 7/400\n","185/185 [==============================] - 10s 55ms/step - loss: 7.5063e-04 - accuracy: 0.1737\n","Epoch 8/400\n","185/185 [==============================] - 10s 55ms/step - loss: 9.3899e-04 - accuracy: 0.1737\n","Epoch 9/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0010 - accuracy: 0.1737\n","Epoch 10/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0014 - accuracy: 0.1736\n","Epoch 11/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0015 - accuracy: 0.1736\n","Epoch 12/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0020 - accuracy: 0.1735\n","Epoch 13/400\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0018 - accuracy: 0.1735\n","Epoch 14/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0028 - accuracy: 0.1733\n","Epoch 15/400\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0030 - accuracy: 0.1732\n","Epoch 16/400\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0034 - accuracy: 0.1732\n","Epoch 17/400\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0039 - accuracy: 0.1731\n","Epoch 18/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0045 - accuracy: 0.1729\n","Epoch 19/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0056 - accuracy: 0.1726\n","Epoch 20/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0063 - accuracy: 0.1725\n","Epoch 21/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0075 - accuracy: 0.1721\n","Epoch 22/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0082 - accuracy: 0.1720\n","Epoch 23/400\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0079 - accuracy: 0.1720\n","Epoch 24/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0078 - accuracy: 0.1720\n","Epoch 25/400\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0071 - accuracy: 0.1723\n","Epoch 26/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0070 - accuracy: 0.1723\n","Epoch 27/400\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0071 - accuracy: 0.1723\n","Epoch 28/400\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0065 - accuracy: 0.1724\n","Epoch 29/400\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0065 - accuracy: 0.1724\n","Epoch 30/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0056 - accuracy: 0.1727\n","Epoch 31/400\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0058 - accuracy: 0.1726\n","Epoch 32/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0058 - accuracy: 0.1726\n","Epoch 33/400\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0055 - accuracy: 0.1727\n","Epoch 34/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0052 - accuracy: 0.1727\n","Epoch 35/400\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0053 - accuracy: 0.1728\n","Epoch 36/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0051 - accuracy: 0.1728\n","Epoch 37/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0050 - accuracy: 0.1728\n","Epoch 38/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0045 - accuracy: 0.1730\n","Epoch 39/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0045 - accuracy: 0.1729\n","Epoch 40/400\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0046 - accuracy: 0.1729\n","Epoch 41/400\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0042 - accuracy: 0.1730\n","Epoch 42/400\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0041 - accuracy: 0.1730\n","Epoch 43/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0036 - accuracy: 0.1731\n","Epoch 44/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0037 - accuracy: 0.1731\n","Epoch 45/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0038 - accuracy: 0.1731\n","Epoch 46/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0034 - accuracy: 0.1732\n","Epoch 47/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0037 - accuracy: 0.1731\n","Epoch 48/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0034 - accuracy: 0.1732\n","Epoch 49/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0032 - accuracy: 0.1732\n","Epoch 50/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0030 - accuracy: 0.1733\n","Epoch 51/400\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0033 - accuracy: 0.1732\n","Epoch 52/400\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0033 - accuracy: 0.1732\n","Epoch 53/400\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0030 - accuracy: 0.1733\n","Epoch 54/400\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0031 - accuracy: 0.1732\n","Epoch 55/400\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0029 - accuracy: 0.1733\n","Epoch 56/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0026 - accuracy: 0.1733\n","Epoch 57/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0028 - accuracy: 0.1734\n","Epoch 58/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0027 - accuracy: 0.1733\n","Epoch 59/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0028 - accuracy: 0.1733\n","Epoch 60/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0026 - accuracy: 0.1733\n","Epoch 61/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0026 - accuracy: 0.1733\n","Epoch 62/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0026 - accuracy: 0.1734\n","Epoch 63/400\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0024 - accuracy: 0.1734\n","Epoch 64/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0024 - accuracy: 0.1734\n","Epoch 65/400\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0023 - accuracy: 0.1734\n","Epoch 66/400\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0025 - accuracy: 0.1734\n","Epoch 67/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0021 - accuracy: 0.1735\n","Epoch 68/400\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0022 - accuracy: 0.1734\n","Epoch 69/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0023 - accuracy: 0.1734\n","Epoch 70/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0021 - accuracy: 0.1735\n","Epoch 71/400\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0019 - accuracy: 0.1735\n","Epoch 72/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0021 - accuracy: 0.1735\n","Epoch 73/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0023 - accuracy: 0.1734\n","Epoch 74/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0018 - accuracy: 0.1735\n","Epoch 75/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0021 - accuracy: 0.1735\n","Epoch 76/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0019 - accuracy: 0.1735\n","Epoch 77/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0020 - accuracy: 0.1735\n","Epoch 78/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0019 - accuracy: 0.1735\n","Epoch 79/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0018 - accuracy: 0.1735\n","Epoch 80/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0020 - accuracy: 0.1735\n","Epoch 81/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0018 - accuracy: 0.1735\n","Epoch 82/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0017 - accuracy: 0.1736\n","Epoch 83/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0017 - accuracy: 0.1736\n","Epoch 84/400\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0016 - accuracy: 0.1735\n","Epoch 85/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0018 - accuracy: 0.1735\n","Epoch 86/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0017 - accuracy: 0.1735\n","Epoch 87/400\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0016 - accuracy: 0.1736\n","Epoch 88/400\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0016 - accuracy: 0.1735\n","Epoch 89/400\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0017 - accuracy: 0.1735\n","Epoch 90/400\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0017 - accuracy: 0.1735\n","Epoch 91/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0017 - accuracy: 0.1735\n","Epoch 92/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0017 - accuracy: 0.1735\n","Epoch 93/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0014 - accuracy: 0.1736\n","Epoch 94/400\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0016 - accuracy: 0.1736\n","Epoch 95/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0016 - accuracy: 0.1735\n","Epoch 96/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0014 - accuracy: 0.1736\n","Epoch 97/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0015 - accuracy: 0.1736\n","Epoch 98/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0016 - accuracy: 0.1736\n","Epoch 99/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0013 - accuracy: 0.1736\n","Epoch 100/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0015 - accuracy: 0.1736\n","Epoch 101/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0015 - accuracy: 0.1736\n","Epoch 102/400\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0014 - accuracy: 0.1736\n","Epoch 103/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0014 - accuracy: 0.1736\n","Epoch 104/400\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0016 - accuracy: 0.1736\n","Epoch 105/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0016 - accuracy: 0.1736\n","Epoch 106/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0013 - accuracy: 0.1736\n","Epoch 107/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0013 - accuracy: 0.1736\n","Epoch 108/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0013 - accuracy: 0.1736\n","Epoch 109/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0014 - accuracy: 0.1736\n","Epoch 110/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0015 - accuracy: 0.1736\n","Epoch 111/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0012 - accuracy: 0.1736\n","Epoch 112/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0013 - accuracy: 0.1736\n","Epoch 113/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0013 - accuracy: 0.1736\n","Epoch 114/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0013 - accuracy: 0.1736\n","Epoch 115/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0013 - accuracy: 0.1736\n","Epoch 116/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0013 - accuracy: 0.1736\n","Epoch 117/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0012 - accuracy: 0.1736\n","Epoch 118/400\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0013 - accuracy: 0.1736\n","Epoch 119/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0012 - accuracy: 0.1736\n","Epoch 120/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0013 - accuracy: 0.1736\n","Epoch 121/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0012 - accuracy: 0.1736\n","Epoch 122/400\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0012 - accuracy: 0.1736\n","Epoch 123/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0013 - accuracy: 0.1736\n","Epoch 124/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0011 - accuracy: 0.1736\n","Epoch 125/400\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0010 - accuracy: 0.1736\n","Epoch 126/400\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0012 - accuracy: 0.1736\n","Epoch 127/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0013 - accuracy: 0.1736\n","Epoch 128/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0012 - accuracy: 0.1736\n","Epoch 129/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0012 - accuracy: 0.1736\n","Epoch 130/400\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0012 - accuracy: 0.1736\n","Epoch 131/400\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0012 - accuracy: 0.1736\n","Epoch 132/400\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0013 - accuracy: 0.1736\n","Epoch 133/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0013 - accuracy: 0.1736\n","Epoch 134/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0012 - accuracy: 0.1736\n","Epoch 135/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0012 - accuracy: 0.1736\n","Epoch 136/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0013 - accuracy: 0.1736\n","Epoch 137/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0011 - accuracy: 0.1736\n","Epoch 138/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0012 - accuracy: 0.1736\n","Epoch 139/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0012 - accuracy: 0.1736\n","Epoch 140/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0011 - accuracy: 0.1736\n","Epoch 141/400\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0012 - accuracy: 0.1736\n","Epoch 142/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0011 - accuracy: 0.1736\n","Epoch 143/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0012 - accuracy: 0.1736\n","Epoch 144/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0010 - accuracy: 0.1736\n","Epoch 145/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0011 - accuracy: 0.1736\n","Epoch 146/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0010 - accuracy: 0.1737\n","Epoch 147/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0010 - accuracy: 0.1736\n","Epoch 148/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0010 - accuracy: 0.1737\n","Epoch 149/400\n","185/185 [==============================] - 10s 55ms/step - loss: 9.7752e-04 - accuracy: 0.1737\n","Epoch 150/400\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0011 - accuracy: 0.1736\n","Epoch 151/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0010 - accuracy: 0.1737\n","Epoch 152/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0012 - accuracy: 0.1736\n","Epoch 153/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0011 - accuracy: 0.1736\n","Epoch 154/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0010 - accuracy: 0.1736\n","Epoch 155/400\n","185/185 [==============================] - 11s 59ms/step - loss: 9.7362e-04 - accuracy: 0.1737\n","Epoch 156/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0011 - accuracy: 0.1736\n","Epoch 157/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0010 - accuracy: 0.1736\n","Epoch 158/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0012 - accuracy: 0.1736\n","Epoch 159/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0010 - accuracy: 0.1736\n","Epoch 160/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0012 - accuracy: 0.1736\n","Epoch 161/400\n","185/185 [==============================] - 10s 56ms/step - loss: 9.7277e-04 - accuracy: 0.1737\n","Epoch 162/400\n","185/185 [==============================] - 10s 56ms/step - loss: 9.2257e-04 - accuracy: 0.1737\n","Epoch 163/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0011 - accuracy: 0.1736\n","Epoch 164/400\n","185/185 [==============================] - 10s 56ms/step - loss: 9.4622e-04 - accuracy: 0.1737\n","Epoch 165/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0012 - accuracy: 0.1736\n","Epoch 166/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0012 - accuracy: 0.1736\n","Epoch 167/400\n","185/185 [==============================] - 10s 56ms/step - loss: 9.9725e-04 - accuracy: 0.1737\n","Epoch 168/400\n","185/185 [==============================] - 10s 57ms/step - loss: 0.0010 - accuracy: 0.1737\n","Epoch 169/400\n","185/185 [==============================] - 10s 56ms/step - loss: 8.9133e-04 - accuracy: 0.1737\n","Epoch 170/400\n","185/185 [==============================] - 10s 56ms/step - loss: 9.5818e-04 - accuracy: 0.1737\n","Epoch 171/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0010 - accuracy: 0.1736\n","Epoch 172/400\n","185/185 [==============================] - 10s 56ms/step - loss: 9.2216e-04 - accuracy: 0.1736\n","Epoch 173/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0010 - accuracy: 0.1737\n","Epoch 174/400\n","185/185 [==============================] - 10s 56ms/step - loss: 8.7341e-04 - accuracy: 0.1737\n","Epoch 175/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0011 - accuracy: 0.1736\n","Epoch 176/400\n","185/185 [==============================] - 10s 56ms/step - loss: 9.9041e-04 - accuracy: 0.1736\n","Epoch 177/400\n","185/185 [==============================] - 10s 56ms/step - loss: 9.5052e-04 - accuracy: 0.1736\n","Epoch 178/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0010 - accuracy: 0.1736\n","Epoch 179/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0010 - accuracy: 0.1737\n","Epoch 180/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0010 - accuracy: 0.1736\n","Epoch 181/400\n","185/185 [==============================] - 10s 56ms/step - loss: 9.5165e-04 - accuracy: 0.1736\n","Epoch 182/400\n","185/185 [==============================] - 10s 56ms/step - loss: 8.7177e-04 - accuracy: 0.1737\n","Epoch 183/400\n","185/185 [==============================] - 10s 56ms/step - loss: 9.1010e-04 - accuracy: 0.1737\n","Epoch 184/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0011 - accuracy: 0.1737\n","Epoch 185/400\n","185/185 [==============================] - 10s 56ms/step - loss: 9.1146e-04 - accuracy: 0.1737\n","Epoch 186/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0010 - accuracy: 0.1736\n","Epoch 187/400\n","185/185 [==============================] - 10s 56ms/step - loss: 9.2523e-04 - accuracy: 0.1736\n","Epoch 188/400\n","185/185 [==============================] - 10s 56ms/step - loss: 9.4270e-04 - accuracy: 0.1737\n","Epoch 189/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0011 - accuracy: 0.1737\n","Epoch 190/400\n","185/185 [==============================] - 10s 56ms/step - loss: 9.5992e-04 - accuracy: 0.1736\n","Epoch 191/400\n","185/185 [==============================] - 10s 56ms/step - loss: 8.2575e-04 - accuracy: 0.1737\n","Epoch 192/400\n","185/185 [==============================] - 10s 56ms/step - loss: 8.5002e-04 - accuracy: 0.1737\n","Epoch 193/400\n","185/185 [==============================] - 10s 56ms/step - loss: 8.7733e-04 - accuracy: 0.1737\n","Epoch 194/400\n","185/185 [==============================] - 10s 56ms/step - loss: 8.9158e-04 - accuracy: 0.1737\n","Epoch 195/400\n","185/185 [==============================] - 10s 56ms/step - loss: 9.4143e-04 - accuracy: 0.1736\n","Epoch 196/400\n","185/185 [==============================] - 10s 56ms/step - loss: 8.8474e-04 - accuracy: 0.1737\n","Epoch 197/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0012 - accuracy: 0.1736\n","Epoch 198/400\n","185/185 [==============================] - 10s 56ms/step - loss: 8.5400e-04 - accuracy: 0.1736\n","Epoch 199/400\n","185/185 [==============================] - 10s 56ms/step - loss: 8.1606e-04 - accuracy: 0.1737\n","Epoch 200/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.4034e-04 - accuracy: 0.1737\n","Epoch 201/400\n","185/185 [==============================] - 10s 56ms/step - loss: 8.4780e-04 - accuracy: 0.1737\n","Epoch 202/400\n","185/185 [==============================] - 10s 56ms/step - loss: 8.6389e-04 - accuracy: 0.1737\n","Epoch 203/400\n","185/185 [==============================] - 10s 56ms/step - loss: 8.7608e-04 - accuracy: 0.1737\n","Epoch 204/400\n","185/185 [==============================] - 10s 56ms/step - loss: 8.9272e-04 - accuracy: 0.1737\n","Epoch 205/400\n","185/185 [==============================] - 10s 56ms/step - loss: 9.3424e-04 - accuracy: 0.1737\n","Epoch 206/400\n","185/185 [==============================] - 10s 56ms/step - loss: 8.9174e-04 - accuracy: 0.1737\n","Epoch 207/400\n","185/185 [==============================] - 10s 56ms/step - loss: 9.7515e-04 - accuracy: 0.1736\n","Epoch 208/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.5525e-04 - accuracy: 0.1737\n","Epoch 209/400\n","185/185 [==============================] - 10s 56ms/step - loss: 9.2130e-04 - accuracy: 0.1737\n","Epoch 210/400\n","185/185 [==============================] - 10s 56ms/step - loss: 8.5508e-04 - accuracy: 0.1737\n","Epoch 211/400\n","185/185 [==============================] - 10s 56ms/step - loss: 9.0792e-04 - accuracy: 0.1737\n","Epoch 212/400\n","185/185 [==============================] - 10s 56ms/step - loss: 8.2705e-04 - accuracy: 0.1737\n","Epoch 213/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.8871e-04 - accuracy: 0.1737\n","Epoch 214/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.6029e-04 - accuracy: 0.1737\n","Epoch 215/400\n","185/185 [==============================] - 10s 56ms/step - loss: 9.3781e-04 - accuracy: 0.1737\n","Epoch 216/400\n","185/185 [==============================] - 10s 56ms/step - loss: 8.4018e-04 - accuracy: 0.1737\n","Epoch 217/400\n","185/185 [==============================] - 10s 56ms/step - loss: 0.0011 - accuracy: 0.1736\n","Epoch 218/400\n","185/185 [==============================] - 10s 56ms/step - loss: 8.3664e-04 - accuracy: 0.1737\n","Epoch 219/400\n","185/185 [==============================] - 10s 55ms/step - loss: 8.9012e-04 - accuracy: 0.1737\n","Epoch 220/400\n","185/185 [==============================] - 10s 56ms/step - loss: 8.2363e-04 - accuracy: 0.1737\n","Epoch 221/400\n","185/185 [==============================] - 10s 56ms/step - loss: 8.4041e-04 - accuracy: 0.1737\n","Epoch 222/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.9875e-04 - accuracy: 0.1737\n","Epoch 223/400\n","185/185 [==============================] - 10s 56ms/step - loss: 8.9824e-04 - accuracy: 0.1737\n","Epoch 224/400\n","185/185 [==============================] - 10s 56ms/step - loss: 8.5838e-04 - accuracy: 0.1737\n","Epoch 225/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.7305e-04 - accuracy: 0.1737\n","Epoch 226/400\n","185/185 [==============================] - 11s 58ms/step - loss: 7.3686e-04 - accuracy: 0.1737\n","Epoch 227/400\n","185/185 [==============================] - 11s 58ms/step - loss: 8.0258e-04 - accuracy: 0.1737\n","Epoch 228/400\n","185/185 [==============================] - 11s 58ms/step - loss: 7.5873e-04 - accuracy: 0.1737\n","Epoch 229/400\n","185/185 [==============================] - 11s 57ms/step - loss: 8.4963e-04 - accuracy: 0.1737\n","Epoch 230/400\n","185/185 [==============================] - 11s 58ms/step - loss: 8.3402e-04 - accuracy: 0.1737\n","Epoch 231/400\n","185/185 [==============================] - 11s 58ms/step - loss: 7.9628e-04 - accuracy: 0.1737\n","Epoch 232/400\n","185/185 [==============================] - 11s 57ms/step - loss: 8.7530e-04 - accuracy: 0.1737\n","Epoch 233/400\n","185/185 [==============================] - 11s 57ms/step - loss: 7.2669e-04 - accuracy: 0.1737\n","Epoch 234/400\n","185/185 [==============================] - 10s 56ms/step - loss: 9.7831e-04 - accuracy: 0.1736\n","Epoch 235/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.7252e-04 - accuracy: 0.1737\n","Epoch 236/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.9208e-04 - accuracy: 0.1737\n","Epoch 237/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.7987e-04 - accuracy: 0.1737\n","Epoch 238/400\n","185/185 [==============================] - 10s 56ms/step - loss: 8.0598e-04 - accuracy: 0.1737\n","Epoch 239/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.1199e-04 - accuracy: 0.1737\n","Epoch 240/400\n","185/185 [==============================] - 10s 56ms/step - loss: 8.2531e-04 - accuracy: 0.1737\n","Epoch 241/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.6828e-04 - accuracy: 0.1737\n","Epoch 242/400\n","185/185 [==============================] - 10s 55ms/step - loss: 8.1510e-04 - accuracy: 0.1737\n","Epoch 243/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.0484e-04 - accuracy: 0.1737\n","Epoch 244/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.6991e-04 - accuracy: 0.1737\n","Epoch 245/400\n","185/185 [==============================] - 10s 56ms/step - loss: 8.8090e-04 - accuracy: 0.1737\n","Epoch 246/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.7781e-04 - accuracy: 0.1737\n","Epoch 247/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.8473e-04 - accuracy: 0.1737\n","Epoch 248/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.6987e-04 - accuracy: 0.1737\n","Epoch 249/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.7394e-04 - accuracy: 0.1737\n","Epoch 250/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.2334e-04 - accuracy: 0.1737\n","Epoch 251/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.0233e-04 - accuracy: 0.1737\n","Epoch 252/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.7985e-04 - accuracy: 0.1737\n","Epoch 253/400\n","185/185 [==============================] - 10s 56ms/step - loss: 8.1352e-04 - accuracy: 0.1737\n","Epoch 254/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.5549e-04 - accuracy: 0.1737\n","Epoch 255/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.9744e-04 - accuracy: 0.1737\n","Epoch 256/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.5669e-04 - accuracy: 0.1737\n","Epoch 257/400\n","185/185 [==============================] - 10s 56ms/step - loss: 8.3409e-04 - accuracy: 0.1737\n","Epoch 258/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.0488e-04 - accuracy: 0.1737\n","Epoch 259/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.5067e-04 - accuracy: 0.1737\n","Epoch 260/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.8712e-04 - accuracy: 0.1737\n","Epoch 261/400\n","185/185 [==============================] - 10s 56ms/step - loss: 8.3269e-04 - accuracy: 0.1737\n","Epoch 262/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.8515e-04 - accuracy: 0.1737\n","Epoch 263/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.7846e-04 - accuracy: 0.1737\n","Epoch 264/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.3440e-04 - accuracy: 0.1737\n","Epoch 265/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.8946e-04 - accuracy: 0.1737\n","Epoch 266/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.9343e-04 - accuracy: 0.1737\n","Epoch 267/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.5298e-04 - accuracy: 0.1737\n","Epoch 268/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.8447e-04 - accuracy: 0.1737\n","Epoch 269/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.9612e-04 - accuracy: 0.1737\n","Epoch 270/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.8349e-04 - accuracy: 0.1737\n","Epoch 271/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.5174e-04 - accuracy: 0.1737\n","Epoch 272/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.7161e-04 - accuracy: 0.1737\n","Epoch 273/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.9538e-04 - accuracy: 0.1737\n","Epoch 274/400\n","185/185 [==============================] - 10s 56ms/step - loss: 8.8553e-04 - accuracy: 0.1737\n","Epoch 275/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.9165e-04 - accuracy: 0.1737\n","Epoch 276/400\n","185/185 [==============================] - 10s 56ms/step - loss: 8.3183e-04 - accuracy: 0.1737\n","Epoch 277/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.5460e-04 - accuracy: 0.1737\n","Epoch 278/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.3719e-04 - accuracy: 0.1737\n","Epoch 279/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.9547e-04 - accuracy: 0.1737\n","Epoch 280/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.2639e-04 - accuracy: 0.1737\n","Epoch 281/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.3713e-04 - accuracy: 0.1737\n","Epoch 282/400\n","185/185 [==============================] - 10s 56ms/step - loss: 8.0589e-04 - accuracy: 0.1737\n","Epoch 283/400\n","185/185 [==============================] - 10s 56ms/step - loss: 8.3162e-04 - accuracy: 0.1737\n","Epoch 284/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.7930e-04 - accuracy: 0.1737\n","Epoch 285/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.5369e-04 - accuracy: 0.1737\n","Epoch 286/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.3421e-04 - accuracy: 0.1737\n","Epoch 287/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.5936e-04 - accuracy: 0.1737\n","Epoch 288/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.2063e-04 - accuracy: 0.1737\n","Epoch 289/400\n","185/185 [==============================] - 10s 56ms/step - loss: 8.2297e-04 - accuracy: 0.1737\n","Epoch 290/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.8332e-04 - accuracy: 0.1737\n","Epoch 291/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.2136e-04 - accuracy: 0.1737\n","Epoch 292/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.8632e-04 - accuracy: 0.1737\n","Epoch 293/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.3443e-04 - accuracy: 0.1737\n","Epoch 294/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.7647e-04 - accuracy: 0.1737\n","Epoch 295/400\n","185/185 [==============================] - 10s 56ms/step - loss: 8.2266e-04 - accuracy: 0.1737\n","Epoch 296/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.7180e-04 - accuracy: 0.1737\n","Epoch 297/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.3656e-04 - accuracy: 0.1737\n","Epoch 298/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.6355e-04 - accuracy: 0.1737\n","Epoch 299/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.0787e-04 - accuracy: 0.1737\n","Epoch 300/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.6167e-04 - accuracy: 0.1737\n","Epoch 301/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.2114e-04 - accuracy: 0.1737\n","Epoch 302/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.9033e-04 - accuracy: 0.1737\n","Epoch 303/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.4459e-04 - accuracy: 0.1737\n","Epoch 304/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.7167e-04 - accuracy: 0.1737\n","Epoch 305/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.6329e-04 - accuracy: 0.1737\n","Epoch 306/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.2070e-04 - accuracy: 0.1737\n","Epoch 307/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.0830e-04 - accuracy: 0.1737\n","Epoch 308/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.5987e-04 - accuracy: 0.1737\n","Epoch 309/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.3689e-04 - accuracy: 0.1737\n","Epoch 310/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.9167e-04 - accuracy: 0.1737\n","Epoch 311/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.9125e-04 - accuracy: 0.1737\n","Epoch 312/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.2997e-04 - accuracy: 0.1737\n","Epoch 313/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.6955e-04 - accuracy: 0.1737\n","Epoch 314/400\n","185/185 [==============================] - 10s 56ms/step - loss: 5.8609e-04 - accuracy: 0.1737\n","Epoch 315/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.3371e-04 - accuracy: 0.1737\n","Epoch 316/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.5517e-04 - accuracy: 0.1737\n","Epoch 317/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.5084e-04 - accuracy: 0.1737\n","Epoch 318/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.9872e-04 - accuracy: 0.1737\n","Epoch 319/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.1020e-04 - accuracy: 0.1737\n","Epoch 320/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.0232e-04 - accuracy: 0.1737\n","Epoch 321/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.0902e-04 - accuracy: 0.1737\n","Epoch 322/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.6472e-04 - accuracy: 0.1737\n","Epoch 323/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.6564e-04 - accuracy: 0.1737\n","Epoch 324/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.9070e-04 - accuracy: 0.1737\n","Epoch 325/400\n","185/185 [==============================] - 10s 57ms/step - loss: 6.7663e-04 - accuracy: 0.1737\n","Epoch 326/400\n","185/185 [==============================] - 10s 56ms/step - loss: 8.0134e-04 - accuracy: 0.1737\n","Epoch 327/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.8736e-04 - accuracy: 0.1737\n","Epoch 328/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.0962e-04 - accuracy: 0.1737\n","Epoch 329/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.9746e-04 - accuracy: 0.1737\n","Epoch 330/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.9382e-04 - accuracy: 0.1737\n","Epoch 331/400\n","185/185 [==============================] - 10s 56ms/step - loss: 5.8728e-04 - accuracy: 0.1737\n","Epoch 332/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.0725e-04 - accuracy: 0.1737\n","Epoch 333/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.8298e-04 - accuracy: 0.1737\n","Epoch 334/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.5576e-04 - accuracy: 0.1737\n","Epoch 335/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.6608e-04 - accuracy: 0.1737\n","Epoch 336/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.0542e-04 - accuracy: 0.1737\n","Epoch 337/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.0964e-04 - accuracy: 0.1737\n","Epoch 338/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.7047e-04 - accuracy: 0.1737\n","Epoch 339/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.4678e-04 - accuracy: 0.1737\n","Epoch 340/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.3132e-04 - accuracy: 0.1737\n","Epoch 341/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.4886e-04 - accuracy: 0.1737\n","Epoch 342/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.4147e-04 - accuracy: 0.1737\n","Epoch 343/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.0381e-04 - accuracy: 0.1737\n","Epoch 344/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.8769e-04 - accuracy: 0.1737\n","Epoch 345/400\n","185/185 [==============================] - 10s 56ms/step - loss: 5.8616e-04 - accuracy: 0.1737\n","Epoch 346/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.1586e-04 - accuracy: 0.1737\n","Epoch 347/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.0742e-04 - accuracy: 0.1737\n","Epoch 348/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.2946e-04 - accuracy: 0.1737\n","Epoch 349/400\n","185/185 [==============================] - 10s 56ms/step - loss: 5.7884e-04 - accuracy: 0.1737\n","Epoch 350/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.5616e-04 - accuracy: 0.1737\n","Epoch 351/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.8335e-04 - accuracy: 0.1737\n","Epoch 352/400\n","185/185 [==============================] - 10s 57ms/step - loss: 6.0820e-04 - accuracy: 0.1737\n","Epoch 353/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.5683e-04 - accuracy: 0.1737\n","Epoch 354/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.8251e-04 - accuracy: 0.1737\n","Epoch 355/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.5429e-04 - accuracy: 0.1737\n","Epoch 356/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.4436e-04 - accuracy: 0.1737\n","Epoch 357/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.4979e-04 - accuracy: 0.1737\n","Epoch 358/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.3956e-04 - accuracy: 0.1737\n","Epoch 359/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.6147e-04 - accuracy: 0.1737\n","Epoch 360/400\n","185/185 [==============================] - 10s 56ms/step - loss: 5.8953e-04 - accuracy: 0.1737\n","Epoch 361/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.9634e-04 - accuracy: 0.1737\n","Epoch 362/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.7947e-04 - accuracy: 0.1737\n","Epoch 363/400\n","185/185 [==============================] - 10s 56ms/step - loss: 5.7190e-04 - accuracy: 0.1737\n","Epoch 364/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.7627e-04 - accuracy: 0.1737\n","Epoch 365/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.6408e-04 - accuracy: 0.1737\n","Epoch 366/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.3353e-04 - accuracy: 0.1737\n","Epoch 367/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.1372e-04 - accuracy: 0.1737\n","Epoch 368/400\n","185/185 [==============================] - 10s 57ms/step - loss: 6.6006e-04 - accuracy: 0.1737\n","Epoch 369/400\n","185/185 [==============================] - 10s 57ms/step - loss: 7.6517e-04 - accuracy: 0.1737\n","Epoch 370/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.5455e-04 - accuracy: 0.1737\n","Epoch 371/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.5795e-04 - accuracy: 0.1737\n","Epoch 372/400\n","185/185 [==============================] - 10s 56ms/step - loss: 5.9282e-04 - accuracy: 0.1737\n","Epoch 373/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.8430e-04 - accuracy: 0.1737\n","Epoch 374/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.9828e-04 - accuracy: 0.1737\n","Epoch 375/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.0276e-04 - accuracy: 0.1737\n","Epoch 376/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.2428e-04 - accuracy: 0.1737\n","Epoch 377/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.9056e-04 - accuracy: 0.1737\n","Epoch 378/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.0930e-04 - accuracy: 0.1737\n","Epoch 379/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.8881e-04 - accuracy: 0.1737\n","Epoch 380/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.4043e-04 - accuracy: 0.1737\n","Epoch 381/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.5493e-04 - accuracy: 0.1737\n","Epoch 382/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.9955e-04 - accuracy: 0.1737\n","Epoch 383/400\n","185/185 [==============================] - 10s 56ms/step - loss: 7.1270e-04 - accuracy: 0.1737\n","Epoch 384/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.6277e-04 - accuracy: 0.1737\n","Epoch 385/400\n","185/185 [==============================] - 10s 56ms/step - loss: 6.8592e-04 - accuracy: 0.1737\n","Epoch 386/400\n","185/185 [==============================] - 10s 55ms/step - loss: 6.4120e-04 - accuracy: 0.1737\n","Epoch 387/400\n","185/185 [==============================] - 10s 55ms/step - loss: 5.6546e-04 - accuracy: 0.1738\n","Epoch 388/400\n","185/185 [==============================] - 10s 55ms/step - loss: 6.5008e-04 - accuracy: 0.1737\n","Epoch 389/400\n","185/185 [==============================] - 10s 55ms/step - loss: 6.0432e-04 - accuracy: 0.1737\n","Epoch 390/400\n","185/185 [==============================] - 10s 55ms/step - loss: 6.3906e-04 - accuracy: 0.1737\n","Epoch 391/400\n","185/185 [==============================] - 10s 55ms/step - loss: 5.9321e-04 - accuracy: 0.1737\n","Epoch 392/400\n","185/185 [==============================] - 10s 55ms/step - loss: 6.7357e-04 - accuracy: 0.1737\n","Epoch 393/400\n","185/185 [==============================] - 10s 55ms/step - loss: 7.2332e-04 - accuracy: 0.1737\n","Epoch 394/400\n","185/185 [==============================] - 10s 55ms/step - loss: 6.5601e-04 - accuracy: 0.1737\n","Epoch 395/400\n","185/185 [==============================] - 10s 55ms/step - loss: 5.7004e-04 - accuracy: 0.1737\n","Epoch 396/400\n","185/185 [==============================] - 10s 55ms/step - loss: 5.9510e-04 - accuracy: 0.1737\n","Epoch 397/400\n","185/185 [==============================] - 10s 55ms/step - loss: 6.3898e-04 - accuracy: 0.1737\n","Epoch 398/400\n","185/185 [==============================] - 10s 55ms/step - loss: 7.0373e-04 - accuracy: 0.1737\n","Epoch 399/400\n","185/185 [==============================] - 10s 55ms/step - loss: 6.1260e-04 - accuracy: 0.1737\n","Epoch 400/400\n","185/185 [==============================] - 10s 55ms/step - loss: 6.5257e-04 - accuracy: 0.1737\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f1d38485210>"]},"metadata":{},"execution_count":76}]},{"cell_type":"code","source":["sentence_generation('집에 가고 싶다')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"y_zaLRV4fsFd","executionInfo":{"status":"ok","timestamp":1645505086668,"user_tz":-540,"elapsed":744,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"8d28f29a-799a-4119-aa14-fae50eb3daee"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["입력 : 집에 가고 싶다\n","출력 : 집이 최고죠 .\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'집이 최고죠 .'"]},"metadata":{},"execution_count":77}]},{"cell_type":"code","source":["sentence_generation('햇볕은 쨍쨍')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"Z8U5JrH2l0dj","executionInfo":{"status":"ok","timestamp":1645505109062,"user_tz":-540,"elapsed":622,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"dd32c194-128e-40bf-e78c-19f9b4d7a0cc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["입력 : 햇볕은 쨍쨍\n","출력 : 광합성 추천합니다 .\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'광합성 추천합니다 .'"]},"metadata":{},"execution_count":78}]},{"cell_type":"code","source":["sentence_generation('좋은 하루')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"iiTy6da_opWN","executionInfo":{"status":"ok","timestamp":1645505109632,"user_tz":-540,"elapsed":581,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"40792217-364c-43db-d4ff-28b994dac5a7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["입력 : 좋은 하루\n","출력 : 수십번 생각이 나나 봐요 .\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'수십번 생각이 나나 봐요 .'"]},"metadata":{},"execution_count":79}]},{"cell_type":"code","source":["sentence_generation('여기는 어디')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"dMa62E3HosTP","executionInfo":{"status":"ok","timestamp":1645505110746,"user_tz":-540,"elapsed":1129,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"208b18c0-aa9a-46d1-f8ff-f01dc8cef63d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["입력 : 여기는 어디\n","출력 : 저는 비밀을 보장해요 . 답답하다면 저에게 말해보세요 .\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'저는 비밀을 보장해요 . 답답하다면 저에게 말해보세요 .'"]},"metadata":{},"execution_count":80}]},{"cell_type":"code","source":["sentence_generation('핸드폰')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"uzxwSL-xotGI","executionInfo":{"status":"ok","timestamp":1645505110748,"user_tz":-540,"elapsed":24,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"8662cd60-b9d1-4ed3-8920-18d84ae72ee5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["입력 : 핸드폰\n","출력 : 시간을 정해보세요 .\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'시간을 정해보세요 .'"]},"metadata":{},"execution_count":81}]},{"cell_type":"code","source":["sentence_generation('너 봤구나')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"jE-tmNCkovig","executionInfo":{"status":"ok","timestamp":1645505111182,"user_tz":-540,"elapsed":450,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"0b2623e3-4f66-487e-84bc-46176107ce49"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["입력 : 너 봤구나\n","출력 : 많이 알면 도움이 되겠죠 .\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'많이 알면 도움이 되겠죠 .'"]},"metadata":{},"execution_count":82}]},{"cell_type":"code","source":["sentence_generation('졸려 죽겠어')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"oPJRyh3loyEf","executionInfo":{"status":"ok","timestamp":1645505111750,"user_tz":-540,"elapsed":576,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"2c9cf386-5b1f-4fb2-99c3-d0841e15c438"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["입력 : 졸려 죽겠어\n","출력 : 한 번 말을 걸어보세요 .\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'한 번 말을 걸어보세요 .'"]},"metadata":{},"execution_count":83}]},{"cell_type":"code","source":["sentence_generation('주말이 언제 올까?')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"nYuMI2ZDo0xr","executionInfo":{"status":"ok","timestamp":1645505112214,"user_tz":-540,"elapsed":478,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"1474a095-ef31-4430-ae3a-7e35cfba8f3f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["입력 : 주말이 언제 올까?\n","출력 : 중요한 건 노력하는 과정이에요 .\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'중요한 건 노력하는 과정이에요 .'"]},"metadata":{},"execution_count":84}]},{"cell_type":"code","source":["sentence_generation('피곤해')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"Vo6jNSoXo46d","executionInfo":{"status":"ok","timestamp":1645505112673,"user_tz":-540,"elapsed":470,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"b916c634-2999-472a-e40e-3eb0e19ff5e8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["입력 : 피곤해\n","출력 : 푹 쉬세요 .\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'푹 쉬세요 .'"]},"metadata":{},"execution_count":85}]},{"cell_type":"markdown","source":["#### 중간 회고  \n","기존의 모델에 400회 epoch를 더하였더니 오히려 출력물의 결과가 기존보다 나빠진 것 같다. 사실 이러한 평가 또한 주관적인 것이라 나빠졌다!라는 확실한 대답은 사람마다 다를 수 있으나, 적어도 내 입장에서는 확실히 기존의 200epoch의 모델이 출력한 결과들이 더 마음에 든다. 그렇기에 이 녀석은 오버피팅이 아닌가 하는 의심을 가지게 되었다."],"metadata":{"id":"vz_hBP91zbKx"}},{"cell_type":"code","source":["learning_rate = CustomSchedule(D_MODEL)\n","\n","optimizer = tf.keras.optimizers.Adam(\n","    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n","\n","def accuracy(y_true, y_pred):\n","  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n","  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n","\n","model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"],"metadata":{"id":"1cL6UI3FyzaG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["EPOCHS = 300\n","model.fit(dataset, epochs=EPOCHS, verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jhlu7yf9yzXd","executionInfo":{"status":"ok","timestamp":1645510638569,"user_tz":-540,"elapsed":4055889,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"161edf3a-eeee-42a8-c4aa-bccfb2db28ac"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/300\n","185/185 [==============================] - 25s 72ms/step - loss: 1.4806 - accuracy: 0.0176\n","Epoch 2/300\n","185/185 [==============================] - 13s 72ms/step - loss: 1.2196 - accuracy: 0.0280\n","Epoch 3/300\n","185/185 [==============================] - 13s 72ms/step - loss: 1.0512 - accuracy: 0.0491\n","Epoch 4/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.9964 - accuracy: 0.0499\n","Epoch 5/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.9565 - accuracy: 0.0504\n","Epoch 6/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.9320 - accuracy: 0.0515\n","Epoch 7/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.9102 - accuracy: 0.0529\n","Epoch 8/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.8892 - accuracy: 0.0540\n","Epoch 9/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.8668 - accuracy: 0.0554\n","Epoch 10/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.8449 - accuracy: 0.0563\n","Epoch 11/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.8207 - accuracy: 0.0575\n","Epoch 12/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.7943 - accuracy: 0.0591\n","Epoch 13/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.7651 - accuracy: 0.0608\n","Epoch 14/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.7338 - accuracy: 0.0629\n","Epoch 15/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.6995 - accuracy: 0.0655\n","Epoch 16/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.6637 - accuracy: 0.0685\n","Epoch 17/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.6260 - accuracy: 0.0719\n","Epoch 18/300\n","185/185 [==============================] - 13s 73ms/step - loss: 0.5880 - accuracy: 0.0763\n","Epoch 19/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.5505 - accuracy: 0.0809\n","Epoch 20/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.5167 - accuracy: 0.0848\n","Epoch 21/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.4869 - accuracy: 0.0885\n","Epoch 22/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.4600 - accuracy: 0.0921\n","Epoch 23/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.4340 - accuracy: 0.0958\n","Epoch 24/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.4103 - accuracy: 0.0989\n","Epoch 25/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.3907 - accuracy: 0.1021\n","Epoch 26/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.3736 - accuracy: 0.1049\n","Epoch 27/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.3583 - accuracy: 0.1076\n","Epoch 28/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.3456 - accuracy: 0.1098\n","Epoch 29/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.3353 - accuracy: 0.1116\n","Epoch 30/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.3250 - accuracy: 0.1135\n","Epoch 31/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.3175 - accuracy: 0.1151\n","Epoch 32/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.3108 - accuracy: 0.1164\n","Epoch 33/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.3031 - accuracy: 0.1179\n","Epoch 34/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.2984 - accuracy: 0.1185\n","Epoch 35/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.2932 - accuracy: 0.1200\n","Epoch 36/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.2878 - accuracy: 0.1211\n","Epoch 37/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.2840 - accuracy: 0.1217\n","Epoch 38/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.2809 - accuracy: 0.1223\n","Epoch 39/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.2772 - accuracy: 0.1233\n","Epoch 40/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.2731 - accuracy: 0.1239\n","Epoch 41/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.2704 - accuracy: 0.1246\n","Epoch 42/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.2675 - accuracy: 0.1252\n","Epoch 43/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.2656 - accuracy: 0.1254\n","Epoch 44/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.2627 - accuracy: 0.1261\n","Epoch 45/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.2608 - accuracy: 0.1264\n","Epoch 46/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.2581 - accuracy: 0.1271\n","Epoch 47/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.2561 - accuracy: 0.1275\n","Epoch 48/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.2542 - accuracy: 0.1278\n","Epoch 49/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.2523 - accuracy: 0.1282\n","Epoch 50/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.2505 - accuracy: 0.1287\n","Epoch 51/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.2490 - accuracy: 0.1289\n","Epoch 52/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.2481 - accuracy: 0.1291\n","Epoch 53/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.2466 - accuracy: 0.1293\n","Epoch 54/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.2450 - accuracy: 0.1297\n","Epoch 55/300\n","185/185 [==============================] - 13s 70ms/step - loss: 0.2439 - accuracy: 0.1300\n","Epoch 56/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.2424 - accuracy: 0.1302\n","Epoch 57/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.2418 - accuracy: 0.1304\n","Epoch 58/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.2399 - accuracy: 0.1307\n","Epoch 59/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.2396 - accuracy: 0.1309\n","Epoch 60/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.2379 - accuracy: 0.1312\n","Epoch 61/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.2373 - accuracy: 0.1311\n","Epoch 62/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.2351 - accuracy: 0.1317\n","Epoch 63/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.2349 - accuracy: 0.1318\n","Epoch 64/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.2342 - accuracy: 0.1318\n","Epoch 65/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.2331 - accuracy: 0.1321\n","Epoch 66/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.2322 - accuracy: 0.1323\n","Epoch 67/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.2312 - accuracy: 0.1325\n","Epoch 68/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.2309 - accuracy: 0.1326\n","Epoch 69/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.2296 - accuracy: 0.1327\n","Epoch 70/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.2291 - accuracy: 0.1330\n","Epoch 71/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.2287 - accuracy: 0.1329\n","Epoch 72/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.2272 - accuracy: 0.1335\n","Epoch 73/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.2269 - accuracy: 0.1332\n","Epoch 74/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.2262 - accuracy: 0.1336\n","Epoch 75/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.2256 - accuracy: 0.1335\n","Epoch 76/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.2240 - accuracy: 0.1339\n","Epoch 77/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.2238 - accuracy: 0.1338\n","Epoch 78/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.2229 - accuracy: 0.1341\n","Epoch 79/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.2229 - accuracy: 0.1341\n","Epoch 80/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.2219 - accuracy: 0.1341\n","Epoch 81/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.2215 - accuracy: 0.1342\n","Epoch 82/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.2207 - accuracy: 0.1344\n","Epoch 83/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.2197 - accuracy: 0.1347\n","Epoch 84/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.2194 - accuracy: 0.1348\n","Epoch 85/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.2190 - accuracy: 0.1348\n","Epoch 86/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.2181 - accuracy: 0.1350\n","Epoch 87/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.2182 - accuracy: 0.1349\n","Epoch 88/300\n","185/185 [==============================] - 13s 73ms/step - loss: 0.2177 - accuracy: 0.1348\n","Epoch 89/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.2165 - accuracy: 0.1351\n","Epoch 90/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.2163 - accuracy: 0.1351\n","Epoch 91/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.2160 - accuracy: 0.1353\n","Epoch 92/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.2158 - accuracy: 0.1354\n","Epoch 93/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.2150 - accuracy: 0.1356\n","Epoch 94/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.2140 - accuracy: 0.1358\n","Epoch 95/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.2141 - accuracy: 0.1356\n","Epoch 96/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.2140 - accuracy: 0.1356\n","Epoch 97/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.2131 - accuracy: 0.1357\n","Epoch 98/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.2125 - accuracy: 0.1359\n","Epoch 99/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.2120 - accuracy: 0.1360\n","Epoch 100/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.2115 - accuracy: 0.1359\n","Epoch 101/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.2117 - accuracy: 0.1359\n","Epoch 102/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.2102 - accuracy: 0.1363\n","Epoch 103/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.2105 - accuracy: 0.1362\n","Epoch 104/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.2093 - accuracy: 0.1364\n","Epoch 105/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.2100 - accuracy: 0.1362\n","Epoch 106/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.2087 - accuracy: 0.1365\n","Epoch 107/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.2089 - accuracy: 0.1366\n","Epoch 108/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.2083 - accuracy: 0.1365\n","Epoch 109/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.2073 - accuracy: 0.1367\n","Epoch 110/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.2075 - accuracy: 0.1368\n","Epoch 111/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.2071 - accuracy: 0.1367\n","Epoch 112/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.2066 - accuracy: 0.1370\n","Epoch 113/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.2060 - accuracy: 0.1369\n","Epoch 114/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.2059 - accuracy: 0.1369\n","Epoch 115/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.2056 - accuracy: 0.1370\n","Epoch 116/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.2052 - accuracy: 0.1371\n","Epoch 117/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.2049 - accuracy: 0.1372\n","Epoch 118/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.2041 - accuracy: 0.1371\n","Epoch 119/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.2042 - accuracy: 0.1372\n","Epoch 120/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.2035 - accuracy: 0.1373\n","Epoch 121/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.2039 - accuracy: 0.1372\n","Epoch 122/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.2030 - accuracy: 0.1374\n","Epoch 123/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.2026 - accuracy: 0.1376\n","Epoch 124/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.2026 - accuracy: 0.1374\n","Epoch 125/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.2021 - accuracy: 0.1375\n","Epoch 126/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.2018 - accuracy: 0.1377\n","Epoch 127/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.2010 - accuracy: 0.1377\n","Epoch 128/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.2013 - accuracy: 0.1377\n","Epoch 129/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.2006 - accuracy: 0.1378\n","Epoch 130/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.2004 - accuracy: 0.1377\n","Epoch 131/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1997 - accuracy: 0.1381\n","Epoch 132/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.2001 - accuracy: 0.1379\n","Epoch 133/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1995 - accuracy: 0.1380\n","Epoch 134/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1991 - accuracy: 0.1381\n","Epoch 135/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1984 - accuracy: 0.1381\n","Epoch 136/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.1984 - accuracy: 0.1382\n","Epoch 137/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1978 - accuracy: 0.1382\n","Epoch 138/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.1981 - accuracy: 0.1384\n","Epoch 139/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1970 - accuracy: 0.1384\n","Epoch 140/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.1966 - accuracy: 0.1384\n","Epoch 141/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1969 - accuracy: 0.1383\n","Epoch 142/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1966 - accuracy: 0.1384\n","Epoch 143/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1957 - accuracy: 0.1387\n","Epoch 144/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.1961 - accuracy: 0.1385\n","Epoch 145/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1956 - accuracy: 0.1386\n","Epoch 146/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.1952 - accuracy: 0.1386\n","Epoch 147/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1940 - accuracy: 0.1387\n","Epoch 148/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1944 - accuracy: 0.1388\n","Epoch 149/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1940 - accuracy: 0.1387\n","Epoch 150/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1938 - accuracy: 0.1389\n","Epoch 151/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1935 - accuracy: 0.1388\n","Epoch 152/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.1934 - accuracy: 0.1389\n","Epoch 153/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1930 - accuracy: 0.1388\n","Epoch 154/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1931 - accuracy: 0.1390\n","Epoch 155/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1920 - accuracy: 0.1391\n","Epoch 156/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1917 - accuracy: 0.1392\n","Epoch 157/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1909 - accuracy: 0.1392\n","Epoch 158/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1910 - accuracy: 0.1393\n","Epoch 159/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1906 - accuracy: 0.1393\n","Epoch 160/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1913 - accuracy: 0.1392\n","Epoch 161/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1900 - accuracy: 0.1393\n","Epoch 162/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1900 - accuracy: 0.1393\n","Epoch 163/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1893 - accuracy: 0.1395\n","Epoch 164/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.1888 - accuracy: 0.1396\n","Epoch 165/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1895 - accuracy: 0.1393\n","Epoch 166/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1884 - accuracy: 0.1395\n","Epoch 167/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1881 - accuracy: 0.1396\n","Epoch 168/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.1884 - accuracy: 0.1396\n","Epoch 169/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1871 - accuracy: 0.1398\n","Epoch 170/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.1874 - accuracy: 0.1397\n","Epoch 171/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1871 - accuracy: 0.1397\n","Epoch 172/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1862 - accuracy: 0.1398\n","Epoch 173/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1864 - accuracy: 0.1397\n","Epoch 174/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1857 - accuracy: 0.1398\n","Epoch 175/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1865 - accuracy: 0.1398\n","Epoch 176/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1855 - accuracy: 0.1398\n","Epoch 177/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1850 - accuracy: 0.1400\n","Epoch 178/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1852 - accuracy: 0.1399\n","Epoch 179/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1843 - accuracy: 0.1400\n","Epoch 180/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1837 - accuracy: 0.1402\n","Epoch 181/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1836 - accuracy: 0.1402\n","Epoch 182/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1830 - accuracy: 0.1401\n","Epoch 183/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1833 - accuracy: 0.1401\n","Epoch 184/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1832 - accuracy: 0.1401\n","Epoch 185/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1830 - accuracy: 0.1401\n","Epoch 186/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1819 - accuracy: 0.1403\n","Epoch 187/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1825 - accuracy: 0.1402\n","Epoch 188/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1814 - accuracy: 0.1404\n","Epoch 189/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.1815 - accuracy: 0.1404\n","Epoch 190/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1811 - accuracy: 0.1404\n","Epoch 191/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1810 - accuracy: 0.1406\n","Epoch 192/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1809 - accuracy: 0.1403\n","Epoch 193/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1809 - accuracy: 0.1404\n","Epoch 194/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1801 - accuracy: 0.1406\n","Epoch 195/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1804 - accuracy: 0.1405\n","Epoch 196/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.1797 - accuracy: 0.1406\n","Epoch 197/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.1787 - accuracy: 0.1408\n","Epoch 198/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.1790 - accuracy: 0.1407\n","Epoch 199/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1792 - accuracy: 0.1408\n","Epoch 200/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1791 - accuracy: 0.1406\n","Epoch 201/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1781 - accuracy: 0.1408\n","Epoch 202/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1779 - accuracy: 0.1408\n","Epoch 203/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1775 - accuracy: 0.1408\n","Epoch 204/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1776 - accuracy: 0.1408\n","Epoch 205/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1771 - accuracy: 0.1409\n","Epoch 206/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1767 - accuracy: 0.1409\n","Epoch 207/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1765 - accuracy: 0.1409\n","Epoch 208/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1761 - accuracy: 0.1410\n","Epoch 209/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1754 - accuracy: 0.1410\n","Epoch 210/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1754 - accuracy: 0.1411\n","Epoch 211/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1754 - accuracy: 0.1412\n","Epoch 212/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1751 - accuracy: 0.1413\n","Epoch 213/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1749 - accuracy: 0.1410\n","Epoch 214/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1746 - accuracy: 0.1412\n","Epoch 215/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1749 - accuracy: 0.1412\n","Epoch 216/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1739 - accuracy: 0.1414\n","Epoch 217/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1743 - accuracy: 0.1412\n","Epoch 218/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1741 - accuracy: 0.1413\n","Epoch 219/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1736 - accuracy: 0.1412\n","Epoch 220/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1737 - accuracy: 0.1413\n","Epoch 221/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1731 - accuracy: 0.1412\n","Epoch 222/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1729 - accuracy: 0.1414\n","Epoch 223/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1721 - accuracy: 0.1415\n","Epoch 224/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1725 - accuracy: 0.1414\n","Epoch 225/300\n","185/185 [==============================] - 13s 73ms/step - loss: 0.1728 - accuracy: 0.1413\n","Epoch 226/300\n","185/185 [==============================] - 13s 73ms/step - loss: 0.1726 - accuracy: 0.1414\n","Epoch 227/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1721 - accuracy: 0.1415\n","Epoch 228/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1712 - accuracy: 0.1417\n","Epoch 229/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1712 - accuracy: 0.1416\n","Epoch 230/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1716 - accuracy: 0.1414\n","Epoch 231/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1716 - accuracy: 0.1415\n","Epoch 232/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1706 - accuracy: 0.1417\n","Epoch 233/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1706 - accuracy: 0.1417\n","Epoch 234/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1702 - accuracy: 0.1417\n","Epoch 235/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1694 - accuracy: 0.1418\n","Epoch 236/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.1701 - accuracy: 0.1415\n","Epoch 237/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1699 - accuracy: 0.1416\n","Epoch 238/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1698 - accuracy: 0.1418\n","Epoch 239/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1697 - accuracy: 0.1416\n","Epoch 240/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1689 - accuracy: 0.1418\n","Epoch 241/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1683 - accuracy: 0.1419\n","Epoch 242/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.1689 - accuracy: 0.1418\n","Epoch 243/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1688 - accuracy: 0.1417\n","Epoch 244/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1684 - accuracy: 0.1418\n","Epoch 245/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1681 - accuracy: 0.1419\n","Epoch 246/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1682 - accuracy: 0.1419\n","Epoch 247/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1679 - accuracy: 0.1420\n","Epoch 248/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1679 - accuracy: 0.1419\n","Epoch 249/300\n","185/185 [==============================] - 13s 73ms/step - loss: 0.1671 - accuracy: 0.1420\n","Epoch 250/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1670 - accuracy: 0.1420\n","Epoch 251/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1673 - accuracy: 0.1420\n","Epoch 252/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1666 - accuracy: 0.1421\n","Epoch 253/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1667 - accuracy: 0.1420\n","Epoch 254/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1665 - accuracy: 0.1420\n","Epoch 255/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1662 - accuracy: 0.1420\n","Epoch 256/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1659 - accuracy: 0.1422\n","Epoch 257/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1654 - accuracy: 0.1421\n","Epoch 258/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1664 - accuracy: 0.1423\n","Epoch 259/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1656 - accuracy: 0.1423\n","Epoch 260/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1650 - accuracy: 0.1424\n","Epoch 261/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1642 - accuracy: 0.1424\n","Epoch 262/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1641 - accuracy: 0.1424\n","Epoch 263/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1647 - accuracy: 0.1424\n","Epoch 264/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1651 - accuracy: 0.1422\n","Epoch 265/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1637 - accuracy: 0.1423\n","Epoch 266/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.1634 - accuracy: 0.1424\n","Epoch 267/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.1642 - accuracy: 0.1424\n","Epoch 268/300\n","185/185 [==============================] - 13s 71ms/step - loss: 0.1639 - accuracy: 0.1426\n","Epoch 269/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1636 - accuracy: 0.1424\n","Epoch 270/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1631 - accuracy: 0.1425\n","Epoch 271/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1630 - accuracy: 0.1424\n","Epoch 272/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1635 - accuracy: 0.1425\n","Epoch 273/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1632 - accuracy: 0.1424\n","Epoch 274/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1622 - accuracy: 0.1426\n","Epoch 275/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1623 - accuracy: 0.1426\n","Epoch 276/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1620 - accuracy: 0.1427\n","Epoch 277/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1622 - accuracy: 0.1426\n","Epoch 278/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1624 - accuracy: 0.1425\n","Epoch 279/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1621 - accuracy: 0.1426\n","Epoch 280/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1617 - accuracy: 0.1427\n","Epoch 281/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1613 - accuracy: 0.1427\n","Epoch 282/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1609 - accuracy: 0.1429\n","Epoch 283/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1615 - accuracy: 0.1426\n","Epoch 284/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1605 - accuracy: 0.1429\n","Epoch 285/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1603 - accuracy: 0.1428\n","Epoch 286/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1609 - accuracy: 0.1427\n","Epoch 287/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1608 - accuracy: 0.1427\n","Epoch 288/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1608 - accuracy: 0.1428\n","Epoch 289/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1604 - accuracy: 0.1428\n","Epoch 290/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1600 - accuracy: 0.1429\n","Epoch 291/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1592 - accuracy: 0.1429\n","Epoch 292/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1587 - accuracy: 0.1431\n","Epoch 293/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1596 - accuracy: 0.1428\n","Epoch 294/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1594 - accuracy: 0.1429\n","Epoch 295/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1590 - accuracy: 0.1429\n","Epoch 296/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1581 - accuracy: 0.1431\n","Epoch 297/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1588 - accuracy: 0.1429\n","Epoch 298/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1590 - accuracy: 0.1431\n","Epoch 299/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1585 - accuracy: 0.1429\n","Epoch 300/300\n","185/185 [==============================] - 13s 72ms/step - loss: 0.1580 - accuracy: 0.1430\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fea10340210>"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["sentence_generation('집에 가고 싶다')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"KzcExxhCy_Nn","executionInfo":{"status":"ok","timestamp":1645510639272,"user_tz":-540,"elapsed":708,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"0935bf5b-fd45-48b6-c220-160484a8d5ac"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["입력 : 집에 가고 싶다\n","출력 : 오늘 일찍 주무세요 .\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'오늘 일찍 주무세요 .'"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["sentence_generation('햇볕은 쨍쨍')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"SIkEepldy_LD","executionInfo":{"status":"ok","timestamp":1645510639684,"user_tz":-540,"elapsed":420,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"c1bb468c-c241-4c2b-9c0c-909465b89c83"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["입력 : 햇볕은 쨍쨍\n","출력 : 너무 신경쓰지마세요 .\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'너무 신경쓰지마세요 .'"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["sentence_generation('좋은 하루')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"vxSWno2ny_Ie","executionInfo":{"status":"ok","timestamp":1645510640228,"user_tz":-540,"elapsed":550,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"bf6b2487-dfe0-4533-89e5-43095156e3d7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["입력 : 좋은 하루\n","출력 : 화장실 가세요 .\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'화장실 가세요 .'"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["sentence_generation('여기는 어디')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"q9yxpjHfy_Fm","executionInfo":{"status":"ok","timestamp":1645510640579,"user_tz":-540,"elapsed":364,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"c0007fe6-c0a8-424e-8f83-2ebfab188e18"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["입력 : 여기는 어디\n","출력 : 지금도 충분해요 .\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'지금도 충분해요 .'"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["sentence_generation('핸드폰')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"fzPBZSTDy_C8","executionInfo":{"status":"ok","timestamp":1645510641212,"user_tz":-540,"elapsed":642,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"fd1f400e-15ce-4994-e51e-6ae8a718ad72"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["입력 : 핸드폰\n","출력 : 뜻대로 되는게 많지 않죠 .\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'뜻대로 되는게 많지 않죠 .'"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["sentence_generation('너 봤구나')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"reTPYdUAzLc6","executionInfo":{"status":"ok","timestamp":1645510641674,"user_tz":-540,"elapsed":468,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"0101ab77-47f1-4e8b-9701-89fb10c4b18b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["입력 : 너 봤구나\n","출력 : 하나씩 하세요 .\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'하나씩 하세요 .'"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["sentence_generation('졸려 죽겠어')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"uZSXpVHQzLaj","executionInfo":{"status":"ok","timestamp":1645510643178,"user_tz":-540,"elapsed":1511,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"a56156ec-fd9c-411e-892a-a01e8ee9cc77"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["입력 : 졸려 죽겠어\n","출력 : 일찍 구매하면 좀 더 저렴하게 살 수 있어요 .\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'일찍 구매하면 좀 더 저렴하게 살 수 있어요 .'"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":["sentence_generation('주말이 언제 올까?')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"7NAkYhskzLXn","executionInfo":{"status":"ok","timestamp":1645510644184,"user_tz":-540,"elapsed":1013,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"cc34a1e6-321c-4440-bd2b-a14db07e7e4d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["입력 : 주말이 언제 올까?\n","출력 : 먼저 연락해서 대화를 이어나가는 게 수월해요 .\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'먼저 연락해서 대화를 이어나가는 게 수월해요 .'"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["sentence_generation('피곤해')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"gW-22hwczLVF","executionInfo":{"status":"ok","timestamp":1645510644678,"user_tz":-540,"elapsed":505,"user":{"displayName":"이창수","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEyDhfp3NadbFTrZ1U4Bppj35UmkhEiuGvN8Bd=s64","userId":"02843279442729753868"}},"outputId":"5c5f04c9-ebba-41e7-9672-4456fc37c79f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["입력 : 피곤해\n","출력 : 지금도 늦지 않았어요 .\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'지금도 늦지 않았어요 .'"]},"metadata":{},"execution_count":39}]},{"cell_type":"markdown","source":["#### 중간 회고  \n","----  \n","하이퍼 파라미터를 조정하여 300 epoch를 돌려보았지만 오히려 좋지 않는 성능을 나타냈다."],"metadata":{"id":"4khhPCa5z5GS"}},{"cell_type":"markdown","source":["## 회고  \n","----  \n","기존의 하이퍼파라미터의 결과가 훨씬 좋았고, epoch를 300정도로 하는 것이 가장 괜찮은 결과를 나타냈다. 의외로 다양한 질문지에도 준수한 답변을 해주었다. 그렇지만 명사형 질문지에 대한 답변은 모든 모델에서 난해하였다. 사실 내가 같은 질문을 받는다고 하여도 굉장히 어려워할 것 같다는 생각이 든다."],"metadata":{"id":"7cIn-u8a2xkK"}}]}